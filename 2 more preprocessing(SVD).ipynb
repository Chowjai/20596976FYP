{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#importing GBM-TP dataset\n",
    "df= pd.read_csv(\"GBM features.csv\")# header=None, skiprows=1)\n",
    "#df = df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "\n",
    "#dropping last 7 rows\n",
    "df = df[:-7]\n",
    "\n",
    "col_list = list()\n",
    "for col in df.columns:\n",
    "    col_list.append(col)\n",
    "\n",
    "CLIs_col_list = col_list[0:13]\n",
    "CLIs_col_list\n",
    "\n",
    "CLIs_df = df.filter(CLIs_col_list, axis=1)\n",
    "\n",
    "#Processed features:\n",
    "key = ['tcga_participant_barcode']\n",
    "\n",
    "numerical_CLIs_list = [\n",
    "    'CLI_years_to_birth', #age\n",
    "    'CLI_days_to_death',  #changed to Overall_Survival\n",
    "    'CLI_date_of_initial_pathologic_diagnosis', #seemes useless, unless we want to generalise that \"technological advancement prolongs life\"?\n",
    "    'CLI_karnofsky_performance_score' #range from 0 to 100. A higher score means the patient is better able to carry out daily activities.\n",
    "]\n",
    "\n",
    "categorical_CLIs_list = [\n",
    "    'CLI_gender',\n",
    "    'CLI_radiation_therapy',    #better convert yes/no to 0/1\n",
    "    'CLI_histological_type',    #3 forms, ['untreated primary (de novo) gbm' 'treated primary gbm', 'glioblastoma multiforme (gbm)']\n",
    "    'CLI_race',             #4 forms, ['white' 'black or african american' nan 'asian']. \n",
    "    'CLI_ethnicity'         #3 forms, [nan 'hispanic or latino' 'not hispanic or latino'].\n",
    "]\n",
    "\n",
    "#Modify df according to processed features:\n",
    "processed_CLIs_df = CLIs_df.filter(key + numerical_CLIs_list + categorical_CLIs_list, axis=1)\n",
    "processed_CLIs_df = processed_CLIs_df[processed_CLIs_df['CLI_days_to_death'].notnull()]\n",
    "processed_CLIs_df.rename(columns={'CLI_days_to_death': 'Overall_Survival'}, inplace=True)\n",
    "processed_CLIs_df\n",
    "\n",
    "#one-hot encoding\n",
    "#for columns which null values exist(all columns except gender), drop_first=false since the categories are not collectively exhausive\n",
    "# -->0 in all categories implies NaN\n",
    "\n",
    "genderDummy = pd.get_dummies(processed_CLIs_df['CLI_gender'],drop_first=True,prefix='CLI_gender')\n",
    "radiationDummy = pd.get_dummies(processed_CLIs_df['CLI_radiation_therapy'],drop_first=False,prefix='CLI_radiation_therapy')\n",
    "histologicalDummy = pd.get_dummies(processed_CLIs_df['CLI_histological_type'],drop_first=False,prefix='CLI_histological_type')\n",
    "raceDummy = pd.get_dummies(processed_CLIs_df['CLI_race'],drop_first=False,prefix='CLI_race')\n",
    "ethnicityDummy = pd.get_dummies(processed_CLIs_df['CLI_ethnicity'],drop_first=False,prefix='CLI_ethnicity')\n",
    "\n",
    "processed_CLIs_df = processed_CLIs_df.drop(columns=['CLI_gender','CLI_radiation_therapy','CLI_histological_type','CLI_race','CLI_ethnicity'])\n",
    "processed_CLIs_df = pd.concat([processed_CLIs_df,genderDummy,radiationDummy,histologicalDummy,raceDummy,ethnicityDummy],axis=1,sort=True)\n",
    "\n",
    "#replace NaN by median CLI_karnofsky_performance_score(80)\n",
    "processed_CLIs_df['CLI_karnofsky_performance_score'].median()\n",
    "\n",
    "#replace NaN by median CLI_karnofsky_performance_score(80)\n",
    "processed_CLIs_df['CLI_karnofsky_performance_score'].fillna(processed_CLIs_df['CLI_karnofsky_performance_score'].median(), inplace=True)\n",
    "\n",
    "# define the datafram for feature and target\n",
    "X = processed_CLIs_df.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1)\n",
    "y = processed_CLIs_df[['Overall_Survival']]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining genomic(SVD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.002080</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>-0.008499</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>-0.006121</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>-0.019911</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>-0.016007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011279</td>\n",
       "      <td>0.080161</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>-0.038336</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.071899</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.076148</td>\n",
       "      <td>0.009189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>-0.001062</td>\n",
       "      <td>-0.008585</td>\n",
       "      <td>-0.011622</td>\n",
       "      <td>-0.008820</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.006126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>-0.002515</td>\n",
       "      <td>0.027093</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.013020</td>\n",
       "      <td>-0.003563</td>\n",
       "      <td>0.034968</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.017326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.004460</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>-0.009462</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>-0.012418</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.009745</td>\n",
       "      <td>0.016754</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>-0.031570</td>\n",
       "      <td>-0.009484</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>-0.014198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>-0.011515</td>\n",
       "      <td>0.082286</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>-0.038595</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>-0.011047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>-0.004112</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>-0.007325</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.005243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>-0.001462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>-0.011276</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>0.005637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001180</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.016403</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.016132</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.018534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>-0.014937</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>-0.008431</td>\n",
       "      <td>-0.010500</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>0.009126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>0.037857</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012760</td>\n",
       "      <td>0.030750</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.004980</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>0.017605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.000117  0.000651  0.000917  0.000605 -0.002080  0.029418 -0.004312   \n",
       "1   -0.011279  0.080161  0.028964  0.022265 -0.000316  0.004716  0.017431   \n",
       "2   -0.000077  0.000458  0.000234  0.000483 -0.000460  0.017371 -0.003057   \n",
       "3   -0.000113  0.000685  0.000639  0.000806 -0.002515  0.027093 -0.004193   \n",
       "4   -0.000218  0.001249  0.001511  0.001492 -0.004460  0.055221 -0.009462   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "590 -0.011515  0.082286  0.007737  0.008163 -0.038595  0.011094  0.001348   \n",
       "591 -0.000142  0.000879  0.001733  0.000691 -0.002792  0.031529 -0.003034   \n",
       "592 -0.000087  0.000545  0.000991  0.000744 -0.002232  0.019648 -0.003206   \n",
       "593 -0.000094  0.000600  0.000689  0.000697 -0.002088  0.020055 -0.003811   \n",
       "594 -0.000162  0.001036  0.002862  0.001116 -0.003637  0.037857 -0.002865   \n",
       "\n",
       "           7         8         9   ...        40        41        42  \\\n",
       "0    0.001773 -0.008499  0.001452  ...  0.016575 -0.013533  0.016591   \n",
       "1   -0.038336  0.013752  0.040128  ...  0.023411  0.001994  0.071899   \n",
       "2    0.000345 -0.003957  0.002566  ... -0.003014 -0.001062 -0.008585   \n",
       "3    0.001727 -0.005622  0.004340  ...  0.004763 -0.013020 -0.003563   \n",
       "4    0.004348 -0.013152 -0.000514  ...  0.009676 -0.012418 -0.000911   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "590 -0.000068  0.003999 -0.011047  ... -0.017285 -0.004112  0.028501   \n",
       "591  0.001699 -0.003018 -0.001462  ...  0.014991 -0.006724  0.007680   \n",
       "592  0.000457 -0.000332  0.002612  ... -0.001180  0.011437 -0.004426   \n",
       "593  0.000368 -0.000472  0.003282  ... -0.000915  0.006502 -0.014937   \n",
       "594  0.001672 -0.002715 -0.004973  ...  0.012760  0.030750  0.003261   \n",
       "\n",
       "           43        44        45        46        47        48        49  \n",
       "0   -0.006121  0.013769 -0.019911  0.008043 -0.030574  0.016663 -0.016007  \n",
       "1    0.028153  0.026566 -0.003987  0.020099  0.009168  0.076148  0.009189  \n",
       "2   -0.011622 -0.008820  0.006360 -0.002060  0.005832 -0.005279  0.006126  \n",
       "3    0.034968  0.025647  0.019994  0.014249  0.018912  0.023333  0.017326  \n",
       "4   -0.009745  0.016754  0.018848 -0.031570 -0.009484  0.048998 -0.014198  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "590 -0.002309 -0.002727 -0.005183 -0.007325  0.016657  0.002386  0.005243  \n",
       "591 -0.011276  0.006180  0.001012 -0.002396  0.018135 -0.014612  0.005637  \n",
       "592  0.016403  0.009157  0.017768  0.016132  0.002826  0.009299  0.018534  \n",
       "593 -0.003251  0.025340  0.030716 -0.008431 -0.010500  0.071337  0.009126  \n",
       "594  0.009781 -0.020969 -0.004980  0.001963  0.002126 -0.002686  0.017605  \n",
       "\n",
       "[595 rows x 50 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#getting genomic features\n",
    "genomic_df = df.drop(df.columns[range(1, 13)],axis=1,inplace=False)\n",
    "#fill null by 0\n",
    "genomic_df_0 = genomic_df.fillna(value=0, inplace = False)\n",
    "genomic_df_0.drop(['tcga_participant_barcode'], axis=1, inplace = True)\n",
    "\n",
    "#SVD\n",
    "# Perform SVD matrix factorization to extract features\n",
    "U, s, V = np.linalg.svd(genomic_df_0.to_numpy(), full_matrices=False)\n",
    "pd.DataFrame(U[:, :50]) # Select the top 50 features out of 595 cols in U\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcga_participant_barcode</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-02-0001</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.00208</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>-0.008499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>-0.006121</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>-0.019911</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>-0.016007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-02-0003</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>0.080161</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>-0.038336</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.071899</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.076148</td>\n",
       "      <td>0.009189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-02-0004</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.00046</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>-0.001062</td>\n",
       "      <td>-0.008585</td>\n",
       "      <td>-0.011622</td>\n",
       "      <td>-0.00882</td>\n",
       "      <td>0.00636</td>\n",
       "      <td>-0.00206</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.006126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-02-0006</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>-0.002515</td>\n",
       "      <td>0.027093</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.01302</td>\n",
       "      <td>-0.003563</td>\n",
       "      <td>0.034968</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.017326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-02-0007</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.00446</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>-0.009462</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>-0.012418</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.009745</td>\n",
       "      <td>0.016754</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>-0.03157</td>\n",
       "      <td>-0.009484</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>-0.014198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>TCGA-87-5896</td>\n",
       "      <td>-0.011515</td>\n",
       "      <td>0.082286</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>-0.038595</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>-0.004112</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>-0.007325</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.005243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>TCGA-OX-A56R</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>0.00768</td>\n",
       "      <td>-0.011276</td>\n",
       "      <td>0.00618</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>0.005637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>TCGA-RR-A6KA</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00118</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.016403</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.016132</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.018534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>TCGA-RR-A6KB</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>-0.014937</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>0.02534</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>-0.008431</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>0.009126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TCGA-RR-A6KC</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>0.037857</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01276</td>\n",
       "      <td>0.03075</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.00498</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>0.017605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tcga_participant_barcode         1         2         3         4  \\\n",
       "0               TCGA-02-0001 -0.000117  0.000651  0.000917  0.000605   \n",
       "1               TCGA-02-0003 -0.011279  0.080161  0.028964  0.022265   \n",
       "2               TCGA-02-0004 -0.000077  0.000458  0.000234  0.000483   \n",
       "3               TCGA-02-0006 -0.000113  0.000685  0.000639  0.000806   \n",
       "4               TCGA-02-0007 -0.000218  0.001249  0.001511  0.001492   \n",
       "..                       ...       ...       ...       ...       ...   \n",
       "590             TCGA-87-5896 -0.011515  0.082286  0.007737  0.008163   \n",
       "591             TCGA-OX-A56R -0.000142  0.000879  0.001733  0.000691   \n",
       "592             TCGA-RR-A6KA -0.000087  0.000545  0.000991  0.000744   \n",
       "593             TCGA-RR-A6KB -0.000094    0.0006  0.000689  0.000697   \n",
       "594             TCGA-RR-A6KC -0.000162  0.001036  0.002862  0.001116   \n",
       "\n",
       "            5         6         7         8         9  ...        41  \\\n",
       "0    -0.00208  0.029418 -0.004312  0.001773 -0.008499  ...  0.016575   \n",
       "1   -0.000316  0.004716  0.017431 -0.038336  0.013752  ...  0.023411   \n",
       "2    -0.00046  0.017371 -0.003057  0.000345 -0.003957  ... -0.003014   \n",
       "3   -0.002515  0.027093 -0.004193  0.001727 -0.005622  ...  0.004763   \n",
       "4    -0.00446  0.055221 -0.009462  0.004348 -0.013152  ...  0.009676   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "590 -0.038595  0.011094  0.001348 -0.000068  0.003999  ... -0.017285   \n",
       "591 -0.002792  0.031529 -0.003034  0.001699 -0.003018  ...  0.014991   \n",
       "592 -0.002232  0.019648 -0.003206  0.000457 -0.000332  ...  -0.00118   \n",
       "593 -0.002088  0.020055 -0.003811  0.000368 -0.000472  ... -0.000915   \n",
       "594 -0.003637  0.037857 -0.002865  0.001672 -0.002715  ...   0.01276   \n",
       "\n",
       "           42        43        44        45        46        47        48  \\\n",
       "0   -0.013533  0.016591 -0.006121  0.013769 -0.019911  0.008043 -0.030574   \n",
       "1    0.001994  0.071899  0.028153  0.026566 -0.003987  0.020099  0.009168   \n",
       "2   -0.001062 -0.008585 -0.011622  -0.00882   0.00636  -0.00206  0.005832   \n",
       "3    -0.01302 -0.003563  0.034968  0.025647  0.019994  0.014249  0.018912   \n",
       "4   -0.012418 -0.000911 -0.009745  0.016754  0.018848  -0.03157 -0.009484   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "590 -0.004112  0.028501 -0.002309 -0.002727 -0.005183 -0.007325  0.016657   \n",
       "591 -0.006724   0.00768 -0.011276   0.00618  0.001012 -0.002396  0.018135   \n",
       "592  0.011437 -0.004426  0.016403  0.009157  0.017768  0.016132  0.002826   \n",
       "593  0.006502 -0.014937 -0.003251   0.02534  0.030716 -0.008431   -0.0105   \n",
       "594   0.03075  0.003261  0.009781 -0.020969  -0.00498  0.001963  0.002126   \n",
       "\n",
       "           49        50  \n",
       "0    0.016663 -0.016007  \n",
       "1    0.076148  0.009189  \n",
       "2   -0.005279  0.006126  \n",
       "3    0.023333  0.017326  \n",
       "4    0.048998 -0.014198  \n",
       "..        ...       ...  \n",
       "590  0.002386  0.005243  \n",
       "591 -0.014612  0.005637  \n",
       "592  0.009299  0.018534  \n",
       "593  0.071337  0.009126  \n",
       "594 -0.002686  0.017605  \n",
       "\n",
       "[595 rows x 51 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_genomic_X = pd.DataFrame(np.column_stack((genomic_df['tcga_participant_barcode'].values, U[:, :50])))\n",
    "SVD_genomic_X = SVD_genomic_X.rename(columns={0: 'tcga_participant_barcode'})\n",
    "SVD_genomic_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#merge CLI and Genomic\n",
    "SVD_full_X = pd.merge(processed_CLIs_df, SVD_genomic_X, on='tcga_participant_barcode', how='inner')\n",
    "SVD_full_X.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1, inplace = True)\n",
    "#normalization\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(SVD_full_X)\n",
    "SVD_full_X = pd.DataFrame(zscore_scaler.transform(SVD_full_X), columns = SVD_full_X.columns)\n",
    "SVD_full_X_train, SVD_full_X_test, y_train, y_test = train_test_split(SVD_full_X, y, test_size=0.2,random_state =42)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#NN\n",
    "sc = StandardScaler()\n",
    "SVD_full_X_train = sc.fit_transform(SVD_full_X_train)\n",
    "SVD_full_X_test = sc.transform(SVD_full_X_test)\n",
    "\n",
    "def build_full_NN(num_input_layer_unit, num_first_layer_unit=17, num_second_layer_unit=8):\n",
    "    # Initialising the ANN\n",
    "    full_NN_model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    full_NN_model.add(Dense(num_first_layer_unit, activation = 'relu', input_dim = num_input_layer_unit))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    full_NN_model.add(Dense(units = num_second_layer_unit, activation = 'relu'))\n",
    "    \"\"\"\n",
    "    # Adding the third hidden layer\n",
    "    full_NN_model.add(Dense(units = 4, activation = 'relu'))\n",
    "    \"\"\"\n",
    "\n",
    "    # Adding the output layer\n",
    "    full_NN_model.add(Dense(units = 1))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    full_NN_model.compile(optimizer = 'Adam', loss = 'mean_squared_error')\n",
    "\n",
    "    return full_NN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLI_years_to_birth</th>\n",
       "      <th>CLI_date_of_initial_pathologic_diagnosis</th>\n",
       "      <th>CLI_karnofsky_performance_score</th>\n",
       "      <th>CLI_gender_male</th>\n",
       "      <th>CLI_radiation_therapy_no</th>\n",
       "      <th>CLI_radiation_therapy_yes</th>\n",
       "      <th>CLI_histological_type_glioblastoma multiforme (gbm)</th>\n",
       "      <th>CLI_histological_type_treated primary gbm</th>\n",
       "      <th>CLI_histological_type_untreated primary (de novo) gbm</th>\n",
       "      <th>CLI_race_asian</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "      <td>4.900000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.404407e-16</td>\n",
       "      <td>-1.746358e-14</td>\n",
       "      <td>-5.991806e-16</td>\n",
       "      <td>-1.404772e-16</td>\n",
       "      <td>-2.379049e-17</td>\n",
       "      <td>-7.625420e-16</td>\n",
       "      <td>1.087565e-16</td>\n",
       "      <td>6.476679e-16</td>\n",
       "      <td>7.794219e-17</td>\n",
       "      <td>4.842498e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.324539e-17</td>\n",
       "      <td>-1.087565e-17</td>\n",
       "      <td>2.489505e-17</td>\n",
       "      <td>2.209117e-17</td>\n",
       "      <td>-9.969350e-18</td>\n",
       "      <td>-9.176333e-18</td>\n",
       "      <td>3.428380e-17</td>\n",
       "      <td>-1.551338e-17</td>\n",
       "      <td>-1.770126e-18</td>\n",
       "      <td>-7.930164e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "      <td>1.001022e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.448415e+00</td>\n",
       "      <td>-2.954339e+00</td>\n",
       "      <td>-5.851225e+00</td>\n",
       "      <td>-1.289590e+00</td>\n",
       "      <td>-4.184017e-01</td>\n",
       "      <td>-2.025874e+00</td>\n",
       "      <td>-2.168145e-01</td>\n",
       "      <td>-2.008475e-01</td>\n",
       "      <td>-3.309263e+00</td>\n",
       "      <td>-1.203859e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.519287e+00</td>\n",
       "      <td>-3.935259e+00</td>\n",
       "      <td>-9.119664e+00</td>\n",
       "      <td>-4.579304e+00</td>\n",
       "      <td>-4.733801e+00</td>\n",
       "      <td>-5.226012e+00</td>\n",
       "      <td>-4.306881e+00</td>\n",
       "      <td>-4.202880e+00</td>\n",
       "      <td>-4.029801e+00</td>\n",
       "      <td>-4.992242e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.260047e-01</td>\n",
       "      <td>-5.782600e-01</td>\n",
       "      <td>1.657745e-01</td>\n",
       "      <td>-1.289590e+00</td>\n",
       "      <td>-4.184017e-01</td>\n",
       "      <td>4.936140e-01</td>\n",
       "      <td>-2.168145e-01</td>\n",
       "      <td>-2.008475e-01</td>\n",
       "      <td>3.021821e-01</td>\n",
       "      <td>-1.203859e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.727077e-01</td>\n",
       "      <td>-4.279548e-01</td>\n",
       "      <td>-2.530344e-01</td>\n",
       "      <td>-3.181532e-01</td>\n",
       "      <td>-3.792977e-01</td>\n",
       "      <td>-3.912963e-01</td>\n",
       "      <td>-3.045517e-01</td>\n",
       "      <td>-3.682996e-01</td>\n",
       "      <td>-3.566997e-01</td>\n",
       "      <td>-3.232522e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.422163e-02</td>\n",
       "      <td>2.137663e-01</td>\n",
       "      <td>1.657745e-01</td>\n",
       "      <td>7.754400e-01</td>\n",
       "      <td>-4.184017e-01</td>\n",
       "      <td>4.936140e-01</td>\n",
       "      <td>-2.168145e-01</td>\n",
       "      <td>-2.008475e-01</td>\n",
       "      <td>3.021821e-01</td>\n",
       "      <td>-1.203859e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.345464e-02</td>\n",
       "      <td>-8.818203e-03</td>\n",
       "      <td>7.104131e-02</td>\n",
       "      <td>-2.845514e-02</td>\n",
       "      <td>-3.246502e-02</td>\n",
       "      <td>-6.278007e-03</td>\n",
       "      <td>-4.386891e-02</td>\n",
       "      <td>4.532424e-02</td>\n",
       "      <td>-7.238473e-02</td>\n",
       "      <td>5.230643e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.857263e-01</td>\n",
       "      <td>8.077860e-01</td>\n",
       "      <td>1.657745e-01</td>\n",
       "      <td>7.754400e-01</td>\n",
       "      <td>-4.184017e-01</td>\n",
       "      <td>4.936140e-01</td>\n",
       "      <td>-2.168145e-01</td>\n",
       "      <td>-2.008475e-01</td>\n",
       "      <td>3.021821e-01</td>\n",
       "      <td>-1.203859e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.438398e-01</td>\n",
       "      <td>3.984234e-01</td>\n",
       "      <td>3.881142e-01</td>\n",
       "      <td>3.569849e-01</td>\n",
       "      <td>2.982261e-01</td>\n",
       "      <td>4.073810e-01</td>\n",
       "      <td>2.595064e-01</td>\n",
       "      <td>3.600823e-01</td>\n",
       "      <td>4.303300e-01</td>\n",
       "      <td>3.487394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.182570e+00</td>\n",
       "      <td>1.797819e+00</td>\n",
       "      <td>1.670024e+00</td>\n",
       "      <td>7.754400e-01</td>\n",
       "      <td>2.390048e+00</td>\n",
       "      <td>4.936140e-01</td>\n",
       "      <td>4.612237e+00</td>\n",
       "      <td>4.978903e+00</td>\n",
       "      <td>3.021821e-01</td>\n",
       "      <td>8.306624e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.743783e+00</td>\n",
       "      <td>5.855512e+00</td>\n",
       "      <td>4.370257e+00</td>\n",
       "      <td>6.313704e+00</td>\n",
       "      <td>7.371368e+00</td>\n",
       "      <td>4.244022e+00</td>\n",
       "      <td>5.084952e+00</td>\n",
       "      <td>5.207944e+00</td>\n",
       "      <td>3.525146e+00</td>\n",
       "      <td>3.811863e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLI_years_to_birth  CLI_date_of_initial_pathologic_diagnosis  \\\n",
       "count        4.900000e+02                              4.900000e+02   \n",
       "mean        -5.404407e-16                             -1.746358e-14   \n",
       "std          1.001022e+00                              1.001022e+00   \n",
       "min         -3.448415e+00                             -2.954339e+00   \n",
       "25%         -5.260047e-01                             -5.782600e-01   \n",
       "50%          4.422163e-02                              2.137663e-01   \n",
       "75%          6.857263e-01                              8.077860e-01   \n",
       "max          2.182570e+00                              1.797819e+00   \n",
       "\n",
       "       CLI_karnofsky_performance_score  CLI_gender_male  \\\n",
       "count                     4.900000e+02     4.900000e+02   \n",
       "mean                     -5.991806e-16    -1.404772e-16   \n",
       "std                       1.001022e+00     1.001022e+00   \n",
       "min                      -5.851225e+00    -1.289590e+00   \n",
       "25%                       1.657745e-01    -1.289590e+00   \n",
       "50%                       1.657745e-01     7.754400e-01   \n",
       "75%                       1.657745e-01     7.754400e-01   \n",
       "max                       1.670024e+00     7.754400e-01   \n",
       "\n",
       "       CLI_radiation_therapy_no  CLI_radiation_therapy_yes  \\\n",
       "count              4.900000e+02               4.900000e+02   \n",
       "mean              -2.379049e-17              -7.625420e-16   \n",
       "std                1.001022e+00               1.001022e+00   \n",
       "min               -4.184017e-01              -2.025874e+00   \n",
       "25%               -4.184017e-01               4.936140e-01   \n",
       "50%               -4.184017e-01               4.936140e-01   \n",
       "75%               -4.184017e-01               4.936140e-01   \n",
       "max                2.390048e+00               4.936140e-01   \n",
       "\n",
       "       CLI_histological_type_glioblastoma multiforme (gbm)  \\\n",
       "count                                       4.900000e+02     \n",
       "mean                                        1.087565e-16     \n",
       "std                                         1.001022e+00     \n",
       "min                                        -2.168145e-01     \n",
       "25%                                        -2.168145e-01     \n",
       "50%                                        -2.168145e-01     \n",
       "75%                                        -2.168145e-01     \n",
       "max                                         4.612237e+00     \n",
       "\n",
       "       CLI_histological_type_treated primary gbm  \\\n",
       "count                               4.900000e+02   \n",
       "mean                                6.476679e-16   \n",
       "std                                 1.001022e+00   \n",
       "min                                -2.008475e-01   \n",
       "25%                                -2.008475e-01   \n",
       "50%                                -2.008475e-01   \n",
       "75%                                -2.008475e-01   \n",
       "max                                 4.978903e+00   \n",
       "\n",
       "       CLI_histological_type_untreated primary (de novo) gbm  CLI_race_asian  \\\n",
       "count                                       4.900000e+02        4.900000e+02   \n",
       "mean                                        7.794219e-17        4.842498e-16   \n",
       "std                                         1.001022e+00        1.001022e+00   \n",
       "min                                        -3.309263e+00       -1.203859e-01   \n",
       "25%                                         3.021821e-01       -1.203859e-01   \n",
       "50%                                         3.021821e-01       -1.203859e-01   \n",
       "75%                                         3.021821e-01       -1.203859e-01   \n",
       "max                                         3.021821e-01        8.306624e+00   \n",
       "\n",
       "       ...            41            42            43            44  \\\n",
       "count  ...  4.900000e+02  4.900000e+02  4.900000e+02  4.900000e+02   \n",
       "mean   ... -5.324539e-17 -1.087565e-17  2.489505e-17  2.209117e-17   \n",
       "std    ...  1.001022e+00  1.001022e+00  1.001022e+00  1.001022e+00   \n",
       "min    ... -3.519287e+00 -3.935259e+00 -9.119664e+00 -4.579304e+00   \n",
       "25%    ... -3.727077e-01 -4.279548e-01 -2.530344e-01 -3.181532e-01   \n",
       "50%    ... -2.345464e-02 -8.818203e-03  7.104131e-02 -2.845514e-02   \n",
       "75%    ...  3.438398e-01  3.984234e-01  3.881142e-01  3.569849e-01   \n",
       "max    ...  5.743783e+00  5.855512e+00  4.370257e+00  6.313704e+00   \n",
       "\n",
       "                 45            46            47            48            49  \\\n",
       "count  4.900000e+02  4.900000e+02  4.900000e+02  4.900000e+02  4.900000e+02   \n",
       "mean  -9.969350e-18 -9.176333e-18  3.428380e-17 -1.551338e-17 -1.770126e-18   \n",
       "std    1.001022e+00  1.001022e+00  1.001022e+00  1.001022e+00  1.001022e+00   \n",
       "min   -4.733801e+00 -5.226012e+00 -4.306881e+00 -4.202880e+00 -4.029801e+00   \n",
       "25%   -3.792977e-01 -3.912963e-01 -3.045517e-01 -3.682996e-01 -3.566997e-01   \n",
       "50%   -3.246502e-02 -6.278007e-03 -4.386891e-02  4.532424e-02 -7.238473e-02   \n",
       "75%    2.982261e-01  4.073810e-01  2.595064e-01  3.600823e-01  4.303300e-01   \n",
       "max    7.371368e+00  4.244022e+00  5.084952e+00  5.207944e+00  3.525146e+00   \n",
       "\n",
       "                 50  \n",
       "count  4.900000e+02  \n",
       "mean  -7.930164e-19  \n",
       "std    1.001022e+00  \n",
       "min   -4.992242e+00  \n",
       "25%   -3.232522e-01  \n",
       "50%    5.230643e-02  \n",
       "75%    3.487394e-01  \n",
       "max    3.811863e+00  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_full_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(356.39,537.3)\n"
     ]
    }
   ],
   "source": [
    "''' Plot loss-iteration for (350, 30, 20) '''\n",
    "SVD_full_NN_model = build_full_NN(64, 30, 20)\n",
    "SVD_full_history = SVD_full_NN_model.fit(SVD_full_X_train, y_train, validation_data=(SVD_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_NN_model.predict(SVD_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_NN_model.predict(SVD_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(first_layer, second_layer, train rmse, test rmse)=(8,4,446.05,532.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,6,422.04,538.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,8,426.64,542.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,10,428.31,542.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,12,428.57,542.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,14,418.07,551.17)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,16,418.97,553.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,18,415.18,540.84)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,20,416.27,533.84)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,22,408.12,537.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,24,419.05,555.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,4,432.95,545.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,6,423.08,531.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,8,417.73,534.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,10,422.07,540.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,12,411.21,528.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,14,420.61,551.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,16,424.32,545.82)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,18,415.26,537.94)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,20,411.15,539.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,22,410.81,530.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,24,409.66,527.49)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,4,428.54,537.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,6,422.25,529.69)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,8,423.01,538.7)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,10,416.6,540.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,12,419.51,533.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,14,411.93,541.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,16,413.13,536.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,18,416.93,540.11)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,20,406.66,537.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,22,411.07,546.78)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,24,410.43,535.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,4,437.35,538.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,6,432.25,538.12)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,8,420.66,539.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,10,409.62,538.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,12,426.45,548.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,14,409.82,544.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,16,411.46,539.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,18,407.64,534.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,20,406.32,537.16)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,22,400.91,545.38)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,24,408.67,543.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,4,430.19,541.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,6,429.07,542.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,8,417.26,538.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,10,422.3,540.95)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,12,412.22,547.12)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,14,415.63,542.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,16,407.84,546.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,18,409.81,532.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,20,405.14,537.77)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,22,407.44,539.95)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,24,402.6,538.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,4,428.45,535.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,6,421.93,540.35)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,8,421.66,542.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,10,409.29,541.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,12,406.54,533.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,14,406.78,537.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,16,409.83,540.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,18,402.51,536.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,20,403.24,531.41)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,22,410.83,538.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,24,405.95,544.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,4,416.52,539.9)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,6,418.76,540.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,8,416.23,549.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,10,411.49,535.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,12,406.75,535.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,14,408.03,535.16)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,16,403.84,532.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,18,403.93,546.06)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,20,400.36,538.99)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,22,403.53,542.84)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,24,401.62,533.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,4,412.03,539.12)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,6,410.77,543.35)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,8,413.37,533.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,10,405.31,542.07)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,12,406.71,539.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,14,399.37,534.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,16,401.99,544.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,18,402.73,542.07)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,20,398.2,530.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,22,393.55,534.19)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,24,401.23,530.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,4,432.04,535.89)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,6,408.59,538.34)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,8,413.11,538.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,10,401.24,531.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,12,404.38,532.29)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,14,403.49,536.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,16,402.82,542.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,18,403.58,531.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,20,407.25,539.58)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,22,400.0,540.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,24,402.75,536.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,4,410.21,535.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,6,404.14,528.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,8,406.49,537.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,10,403.49,538.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,12,406.58,536.95)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,14,403.69,536.42)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,16,398.23,536.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,18,404.87,526.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,20,403.17,545.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,22,396.0,542.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,24,397.92,530.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,4,407.02,537.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,6,414.78,533.75)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,8,408.18,547.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,10,405.06,539.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,12,404.04,541.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,14,407.51,533.27)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,16,402.39,533.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,18,404.76,544.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,20,393.34,530.78)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,22,405.06,535.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,24,393.65,533.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,4,743.51,707.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,6,404.16,538.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,8,411.99,536.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,10,402.32,537.45)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,12,400.83,538.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,14,400.69,533.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,16,402.19,532.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,18,400.43,538.95)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,20,394.58,538.52)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,22,397.9,529.84)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,24,396.21,539.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,4,412.74,543.59)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,6,411.64,538.86)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,8,410.71,539.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,10,402.35,535.18)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,12,410.87,533.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,14,396.34,540.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,16,396.27,538.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,18,401.21,531.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,20,397.65,537.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,22,396.48,536.15)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,24,393.3,538.55)\n"
     ]
    }
   ],
   "source": [
    "#try different number of units in each hidden layer\n",
    "num_hidden_unit= list()\n",
    "for  x in range(8, 34,2):\n",
    "    for y in range(4, 26,2):\n",
    "        num_hidden_unit.append((x,y))\n",
    "\n",
    "rmse_for_each_num_hidden = list()\n",
    "for a, b in num_hidden_unit:\n",
    "    SVD_full_NN_model = build_full_NN(64, a, b)\n",
    "    SVD_full_history = SVD_full_NN_model.fit(SVD_full_X_train, y_train, validation_data=(SVD_full_X_test, y_test), batch_size = 10, epochs = 50, verbose = 0)\n",
    "    train_rms = mean_squared_error(y_train, SVD_full_NN_model.predict(SVD_full_X_train, verbose=0), squared=False)\n",
    "    test_rms = mean_squared_error(y_test, SVD_full_NN_model.predict(SVD_full_X_test, verbose=0), squared=False)\n",
    "\n",
    "    print(f\"(first_layer, second_layer, train rmse, test rmse)=({a},{b},{round(train_rms, 2)},{round(test_rms, 2)})\")\n",
    "    rmse_for_each_num_hidden.append((a,b,train_rms,test_rms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 18, 404.86674625919716, 526.560382630491)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_for_each_num_hidden, key = lambda t: t[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much worse(+80) than lasso-selected NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "now try again but only use lasso selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLI_years_to_birth</th>\n",
       "      <th>CLI_date_of_initial_pathologic_diagnosis</th>\n",
       "      <th>CLI_karnofsky_performance_score</th>\n",
       "      <th>CLI_gender_male</th>\n",
       "      <th>CLI_radiation_therapy_no</th>\n",
       "      <th>CLI_radiation_therapy_yes</th>\n",
       "      <th>CLI_histological_type_glioblastoma multiforme (gbm)</th>\n",
       "      <th>CLI_histological_type_treated primary gbm</th>\n",
       "      <th>CLI_histological_type_untreated primary (de novo) gbm</th>\n",
       "      <th>CLI_race_asian</th>\n",
       "      <th>CLI_race_black or african american</th>\n",
       "      <th>CLI_race_white</th>\n",
       "      <th>CLI_ethnicity_hispanic or latino</th>\n",
       "      <th>CLI_ethnicity_not hispanic or latino</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>0.047704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053342</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035137</td>\n",
       "      <td>-0.011198</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.008546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>0.004509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054907</td>\n",
       "      <td>-0.005486</td>\n",
       "      <td>0.014762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>68.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057237</td>\n",
       "      <td>-0.020983</td>\n",
       "      <td>-0.090552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>72.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03763</td>\n",
       "      <td>-0.003884</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>55.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>-0.00492</td>\n",
       "      <td>0.004668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CLI_years_to_birth  CLI_date_of_initial_pathologic_diagnosis  \\\n",
       "0                  44.0                                    2002.0   \n",
       "1                  50.0                                    2003.0   \n",
       "2                  59.0                                    2002.0   \n",
       "3                  56.0                                    2002.0   \n",
       "4                  40.0                                    2002.0   \n",
       "..                  ...                                       ...   \n",
       "485                44.0                                    2011.0   \n",
       "486                64.0                                    2009.0   \n",
       "487                68.0                                    2012.0   \n",
       "488                72.0                                    2012.0   \n",
       "489                55.0                                    2010.0   \n",
       "\n",
       "     CLI_karnofsky_performance_score  CLI_gender_male  \\\n",
       "0                               80.0                0   \n",
       "1                              100.0                1   \n",
       "2                               80.0                1   \n",
       "3                               80.0                0   \n",
       "4                               80.0                0   \n",
       "..                               ...              ...   \n",
       "485                             80.0                0   \n",
       "486                             40.0                1   \n",
       "487                             80.0                1   \n",
       "488                             80.0                0   \n",
       "489                             80.0                1   \n",
       "\n",
       "     CLI_radiation_therapy_no  CLI_radiation_therapy_yes  \\\n",
       "0                           0                          1   \n",
       "1                           0                          1   \n",
       "2                           0                          1   \n",
       "3                           0                          1   \n",
       "4                           0                          1   \n",
       "..                        ...                        ...   \n",
       "485                         0                          1   \n",
       "486                         1                          0   \n",
       "487                         0                          0   \n",
       "488                         1                          0   \n",
       "489                         0                          1   \n",
       "\n",
       "     CLI_histological_type_glioblastoma multiforme (gbm)  \\\n",
       "0                                                    0     \n",
       "1                                                    0     \n",
       "2                                                    0     \n",
       "3                                                    0     \n",
       "4                                                    0     \n",
       "..                                                 ...     \n",
       "485                                                  0     \n",
       "486                                                  0     \n",
       "487                                                  1     \n",
       "488                                                  1     \n",
       "489                                                  1     \n",
       "\n",
       "     CLI_histological_type_treated primary gbm  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            1   \n",
       "..                                         ...   \n",
       "485                                          0   \n",
       "486                                          0   \n",
       "487                                          0   \n",
       "488                                          0   \n",
       "489                                          0   \n",
       "\n",
       "     CLI_histological_type_untreated primary (de novo) gbm  CLI_race_asian  \\\n",
       "0                                                    1                   0   \n",
       "1                                                    1                   0   \n",
       "2                                                    1                   0   \n",
       "3                                                    1                   0   \n",
       "4                                                    0                   0   \n",
       "..                                                 ...                 ...   \n",
       "485                                                  1                   0   \n",
       "486                                                  1                   0   \n",
       "487                                                  0                   0   \n",
       "488                                                  0                   0   \n",
       "489                                                  0                   0   \n",
       "\n",
       "     CLI_race_black or african american  CLI_race_white  \\\n",
       "0                                     0               1   \n",
       "1                                     0               1   \n",
       "2                                     0               1   \n",
       "3                                     0               1   \n",
       "4                                     0               1   \n",
       "..                                  ...             ...   \n",
       "485                                   0               1   \n",
       "486                                   0               1   \n",
       "487                                   1               0   \n",
       "488                                   1               0   \n",
       "489                                   1               0   \n",
       "\n",
       "     CLI_ethnicity_hispanic or latino  CLI_ethnicity_not hispanic or latino  \\\n",
       "0                                   0                                     1   \n",
       "1                                   0                                     1   \n",
       "2                                   0                                     1   \n",
       "3                                   0                                     1   \n",
       "4                                   0                                     1   \n",
       "..                                ...                                   ...   \n",
       "485                                 0                                     0   \n",
       "486                                 0                                     0   \n",
       "487                                 0                                     1   \n",
       "488                                 0                                     1   \n",
       "489                                 0                                     1   \n",
       "\n",
       "            1         2         3  \n",
       "0    0.000016 -0.039306  0.047704  \n",
       "1    0.053342 -0.005596     0.009  \n",
       "2        -0.0       0.0      -0.0  \n",
       "3    0.035137 -0.011198  0.007489  \n",
       "4    0.002035 -0.001032 -0.008546  \n",
       "..        ...       ...       ...  \n",
       "485  0.033021 -0.003121  0.004509  \n",
       "486  0.054907 -0.005486  0.014762  \n",
       "487  0.057237 -0.020983 -0.090552  \n",
       "488   0.03763 -0.003884 -0.000259  \n",
       "489  0.044155  -0.00492  0.004668  \n",
       "\n",
       "[490 rows x 17 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_genomic_df_0 = genomic_df_0[[\"SMG_mutsig2.0_SFT2D1_cosmic\",\"Amp_8q24.21 \",\"Del_1p36.32 \",\"Del_10p11.23\",\"CN_1p_Amp\"]]\n",
    "\n",
    "#SVD\n",
    "# Perform SVD matrix factorization to extract features\n",
    "U, s, V = np.linalg.svd(lasso_genomic_df_0.to_numpy(), full_matrices=False)\n",
    "pd.DataFrame(U) # Select the top 3 features out of 595 cols in U\n",
    "\n",
    "\n",
    "SVD_lasso_genomic_X = pd.DataFrame(np.column_stack((genomic_df['tcga_participant_barcode'].values, U[:, :3])))\n",
    "SVD_lasso_genomic_X = SVD_lasso_genomic_X.rename(columns={0: 'tcga_participant_barcode'})\n",
    "\n",
    "\n",
    "#merge CLI and Genomic\n",
    "SVD_lasso_full_X = pd.merge(processed_CLIs_df, SVD_lasso_genomic_X, on='tcga_participant_barcode', how='inner')\n",
    "SVD_lasso_full_X.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1, inplace = True)\n",
    "SVD_lasso_full_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLI_years_to_birth</th>\n",
       "      <th>CLI_date_of_initial_pathologic_diagnosis</th>\n",
       "      <th>CLI_karnofsky_performance_score</th>\n",
       "      <th>CLI_gender_male</th>\n",
       "      <th>CLI_radiation_therapy_no</th>\n",
       "      <th>CLI_radiation_therapy_yes</th>\n",
       "      <th>CLI_histological_type_glioblastoma multiforme (gbm)</th>\n",
       "      <th>CLI_histological_type_treated primary gbm</th>\n",
       "      <th>CLI_histological_type_untreated primary (de novo) gbm</th>\n",
       "      <th>CLI_race_asian</th>\n",
       "      <th>CLI_race_black or african american</th>\n",
       "      <th>CLI_race_white</th>\n",
       "      <th>CLI_ethnicity_hispanic or latino</th>\n",
       "      <th>CLI_ethnicity_not hispanic or latino</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.024953</td>\n",
       "      <td>-0.380253</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>-1.28959</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>-1.548412</td>\n",
       "      <td>-1.035873</td>\n",
       "      <td>1.144515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.597283</td>\n",
       "      <td>-0.182247</td>\n",
       "      <td>1.670024</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.845347</td>\n",
       "      <td>-0.166844</td>\n",
       "      <td>0.219410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044222</td>\n",
       "      <td>-0.380253</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>-1.549115</td>\n",
       "      <td>-0.022581</td>\n",
       "      <td>0.004304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.169613</td>\n",
       "      <td>-0.380253</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>-1.28959</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.028141</td>\n",
       "      <td>-0.311263</td>\n",
       "      <td>0.183297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.310066</td>\n",
       "      <td>-0.380253</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>-1.28959</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>4.978903</td>\n",
       "      <td>-3.309263</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>-1.457764</td>\n",
       "      <td>-0.049185</td>\n",
       "      <td>-0.199955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-1.024953</td>\n",
       "      <td>1.401806</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>-1.28959</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>-2.230607</td>\n",
       "      <td>-0.066840</td>\n",
       "      <td>-0.103037</td>\n",
       "      <td>0.112085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.400613</td>\n",
       "      <td>1.005793</td>\n",
       "      <td>-2.842725</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>2.390048</td>\n",
       "      <td>-2.025874</td>\n",
       "      <td>-0.216815</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>-0.268719</td>\n",
       "      <td>0.373544</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>-2.230607</td>\n",
       "      <td>0.915602</td>\n",
       "      <td>-0.163995</td>\n",
       "      <td>0.357136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.685726</td>\n",
       "      <td>1.599812</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>-2.025874</td>\n",
       "      <td>4.612237</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>-3.309263</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>3.721355</td>\n",
       "      <td>-2.677063</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>1.020190</td>\n",
       "      <td>-0.563503</td>\n",
       "      <td>-2.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.970839</td>\n",
       "      <td>1.599812</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>-1.28959</td>\n",
       "      <td>2.390048</td>\n",
       "      <td>-2.025874</td>\n",
       "      <td>4.612237</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>-3.309263</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>3.721355</td>\n",
       "      <td>-2.677063</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.140070</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>-0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>-0.240892</td>\n",
       "      <td>1.203799</td>\n",
       "      <td>0.165774</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>-0.418402</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>4.612237</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>-3.309263</td>\n",
       "      <td>-0.120386</td>\n",
       "      <td>3.721355</td>\n",
       "      <td>-2.677063</td>\n",
       "      <td>-0.144338</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.432925</td>\n",
       "      <td>-0.149412</td>\n",
       "      <td>0.115885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CLI_years_to_birth  CLI_date_of_initial_pathologic_diagnosis  \\\n",
       "0             -1.024953                                 -0.380253   \n",
       "1             -0.597283                                 -0.182247   \n",
       "2              0.044222                                 -0.380253   \n",
       "3             -0.169613                                 -0.380253   \n",
       "4             -1.310066                                 -0.380253   \n",
       "..                  ...                                       ...   \n",
       "485           -1.024953                                  1.401806   \n",
       "486            0.400613                                  1.005793   \n",
       "487            0.685726                                  1.599812   \n",
       "488            0.970839                                  1.599812   \n",
       "489           -0.240892                                  1.203799   \n",
       "\n",
       "     CLI_karnofsky_performance_score  CLI_gender_male  \\\n",
       "0                           0.165774         -1.28959   \n",
       "1                           1.670024          0.77544   \n",
       "2                           0.165774          0.77544   \n",
       "3                           0.165774         -1.28959   \n",
       "4                           0.165774         -1.28959   \n",
       "..                               ...              ...   \n",
       "485                         0.165774         -1.28959   \n",
       "486                        -2.842725          0.77544   \n",
       "487                         0.165774          0.77544   \n",
       "488                         0.165774         -1.28959   \n",
       "489                         0.165774          0.77544   \n",
       "\n",
       "     CLI_radiation_therapy_no  CLI_radiation_therapy_yes  \\\n",
       "0                   -0.418402                   0.493614   \n",
       "1                   -0.418402                   0.493614   \n",
       "2                   -0.418402                   0.493614   \n",
       "3                   -0.418402                   0.493614   \n",
       "4                   -0.418402                   0.493614   \n",
       "..                        ...                        ...   \n",
       "485                 -0.418402                   0.493614   \n",
       "486                  2.390048                  -2.025874   \n",
       "487                 -0.418402                  -2.025874   \n",
       "488                  2.390048                  -2.025874   \n",
       "489                 -0.418402                   0.493614   \n",
       "\n",
       "     CLI_histological_type_glioblastoma multiforme (gbm)  \\\n",
       "0                                            -0.216815     \n",
       "1                                            -0.216815     \n",
       "2                                            -0.216815     \n",
       "3                                            -0.216815     \n",
       "4                                            -0.216815     \n",
       "..                                                 ...     \n",
       "485                                          -0.216815     \n",
       "486                                          -0.216815     \n",
       "487                                           4.612237     \n",
       "488                                           4.612237     \n",
       "489                                           4.612237     \n",
       "\n",
       "     CLI_histological_type_treated primary gbm  \\\n",
       "0                                    -0.200847   \n",
       "1                                    -0.200847   \n",
       "2                                    -0.200847   \n",
       "3                                    -0.200847   \n",
       "4                                     4.978903   \n",
       "..                                         ...   \n",
       "485                                  -0.200847   \n",
       "486                                  -0.200847   \n",
       "487                                  -0.200847   \n",
       "488                                  -0.200847   \n",
       "489                                  -0.200847   \n",
       "\n",
       "     CLI_histological_type_untreated primary (de novo) gbm  CLI_race_asian  \\\n",
       "0                                             0.302182           -0.120386   \n",
       "1                                             0.302182           -0.120386   \n",
       "2                                             0.302182           -0.120386   \n",
       "3                                             0.302182           -0.120386   \n",
       "4                                            -3.309263           -0.120386   \n",
       "..                                                 ...                 ...   \n",
       "485                                           0.302182           -0.120386   \n",
       "486                                           0.302182           -0.120386   \n",
       "487                                          -3.309263           -0.120386   \n",
       "488                                          -3.309263           -0.120386   \n",
       "489                                          -3.309263           -0.120386   \n",
       "\n",
       "     CLI_race_black or african american  CLI_race_white  \\\n",
       "0                             -0.268719        0.373544   \n",
       "1                             -0.268719        0.373544   \n",
       "2                             -0.268719        0.373544   \n",
       "3                             -0.268719        0.373544   \n",
       "4                             -0.268719        0.373544   \n",
       "..                                  ...             ...   \n",
       "485                           -0.268719        0.373544   \n",
       "486                           -0.268719        0.373544   \n",
       "487                            3.721355       -2.677063   \n",
       "488                            3.721355       -2.677063   \n",
       "489                            3.721355       -2.677063   \n",
       "\n",
       "     CLI_ethnicity_hispanic or latino  CLI_ethnicity_not hispanic or latino  \\\n",
       "0                           -0.144338                              0.448308   \n",
       "1                           -0.144338                              0.448308   \n",
       "2                           -0.144338                              0.448308   \n",
       "3                           -0.144338                              0.448308   \n",
       "4                           -0.144338                              0.448308   \n",
       "..                                ...                                   ...   \n",
       "485                         -0.144338                             -2.230607   \n",
       "486                         -0.144338                             -2.230607   \n",
       "487                         -0.144338                              0.448308   \n",
       "488                         -0.144338                              0.448308   \n",
       "489                         -0.144338                              0.448308   \n",
       "\n",
       "            1         2         3  \n",
       "0   -1.548412 -1.035873  1.144515  \n",
       "1    0.845347 -0.166844  0.219410  \n",
       "2   -1.549115 -0.022581  0.004304  \n",
       "3    0.028141 -0.311263  0.183297  \n",
       "4   -1.457764 -0.049185 -0.199955  \n",
       "..        ...       ...       ...  \n",
       "485 -0.066840 -0.103037  0.112085  \n",
       "486  0.915602 -0.163995  0.357136  \n",
       "487  1.020190 -0.563503 -2.160037  \n",
       "488  0.140070 -0.122716 -0.001883  \n",
       "489  0.432925 -0.149412  0.115885  \n",
       "\n",
       "[490 rows x 17 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalization\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(SVD_lasso_full_X)\n",
    "SVD_lasso_full_X = pd.DataFrame(zscore_scaler.transform(SVD_lasso_full_X), columns = SVD_lasso_full_X.columns)\n",
    "SVD_lasso_full_X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.47175025, -0.17383308, -2.73306647, ...,  0.37324636,\n",
       "        -0.03085972,  0.06479468],\n",
       "       [-0.01563028,  0.63258784,  0.91847428, ..., -0.13953002,\n",
       "         0.37691107,  0.48170706],\n",
       "       [ 0.47175025,  0.83419307, -1.27245017, ...,  0.79607266,\n",
       "         1.34675517, -0.03611593],\n",
       "       ...,\n",
       "       [ 0.54137604,  0.43098261, -1.27245017, ...,  0.42440512,\n",
       "        -0.11961839,  0.26119711],\n",
       "       [ 0.75025341,  0.83419307,  0.18816613, ...,  0.21461173,\n",
       "        -0.13477595,  0.08660826],\n",
       "       [ 0.26287288, -0.77864877,  0.18816613, ..., -1.05756101,\n",
       "         0.03022644,  0.05117877]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = processed_CLIs_df[['Overall_Survival']]\n",
    "SVD_lasso_full_X_train, SVD_lasso_full_X_test, y_train, y_test = train_test_split(SVD_lasso_full_X, y, test_size=0.2,random_state =42)\n",
    "#NN\n",
    "sc = StandardScaler()\n",
    "SVD_lasso_full_X_train = sc.fit_transform(SVD_lasso_full_X_train)\n",
    "SVD_lasso_full_X_test = sc.transform(SVD_lasso_full_X_test)\n",
    "SVD_lasso_full_X_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(405.74,482.01)\n"
     ]
    }
   ],
   "source": [
    "''' Plot loss-iteration for (30, 20) '''\n",
    "SVD_full_lasso_NN_model = build_full_NN(17,30, 20)\n",
    "SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_lasso_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_lasso_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(first_layer, second_layer, train rmse, test rmse)=(8,4,439.77,499.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,6,440.52,498.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,8,437.58,499.82)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,10,438.68,496.28)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,12,437.81,497.7)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,14,430.51,498.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,16,423.3,495.14)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,18,431.86,479.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,20,419.72,460.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,22,427.72,487.08)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,24,436.94,499.37)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,4,448.45,523.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,6,434.99,497.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,8,442.11,517.58)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,10,433.39,497.35)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,12,428.13,482.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,14,422.79,482.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,16,430.3,496.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,18,432.24,507.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,20,428.28,493.19)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,22,426.75,501.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,24,429.05,500.41)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,4,445.88,504.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,6,441.34,505.98)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,8,430.36,489.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,10,437.26,509.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,12,436.69,497.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,14,425.71,485.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,16,424.55,488.62)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,18,418.95,484.6)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,20,431.05,485.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,22,426.79,496.29)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,24,423.37,482.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,4,740.94,704.59)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,6,421.03,479.67)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,8,430.83,498.18)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,10,420.95,485.98)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,12,427.85,494.59)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,14,420.21,476.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,16,423.53,482.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,18,427.54,490.57)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,20,415.17,482.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,22,418.3,485.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,24,418.99,478.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,4,433.67,496.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,6,424.85,488.78)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,8,427.56,499.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,10,426.75,486.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,12,425.92,493.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,14,417.38,477.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,16,422.03,481.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,18,416.86,478.82)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,20,419.88,491.65)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,22,414.22,471.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,24,409.89,488.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,4,427.7,491.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,6,435.31,489.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,8,426.1,490.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,10,426.89,487.41)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,12,424.69,490.06)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,14,421.21,481.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,16,417.72,484.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,18,425.86,487.19)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,20,422.09,485.08)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,22,409.8,475.7)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,24,423.19,471.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,4,430.37,484.45)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,6,428.54,498.86)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,8,431.84,482.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,10,426.26,492.92)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,12,422.36,491.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,14,424.52,483.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,16,417.3,487.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,18,419.42,475.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,20,412.89,464.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,22,418.8,483.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,24,414.15,486.58)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,4,433.82,500.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,6,417.32,477.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,8,419.56,484.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,10,430.63,495.69)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,12,421.68,489.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,14,413.15,476.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,16,419.39,486.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,18,422.48,488.12)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,20,424.37,500.04)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,22,416.77,486.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,24,416.72,479.77)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,4,424.41,482.72)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,6,422.37,497.29)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,8,423.52,491.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,10,414.49,487.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,12,421.34,483.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,14,426.69,488.29)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,16,417.88,483.38)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,18,414.4,469.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,20,413.38,480.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,22,411.28,483.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,24,417.14,480.98)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,4,421.11,483.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,6,423.4,486.87)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,8,415.33,491.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,10,419.41,481.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,12,417.88,478.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,14,416.97,482.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,16,411.85,483.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,18,411.93,488.86)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,20,418.6,480.85)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,22,415.04,485.46)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,24,407.58,467.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,4,422.99,477.6)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,6,420.53,481.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,8,423.14,492.8)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,10,436.38,501.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,12,420.73,483.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,14,411.45,482.58)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,16,409.32,485.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,18,412.72,479.38)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,20,407.06,477.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,22,404.14,475.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,24,413.7,474.14)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,4,431.71,500.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,6,414.28,483.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,8,417.0,482.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,10,410.63,484.12)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,12,412.6,482.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,14,418.62,481.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,16,415.72,490.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,18,414.72,486.57)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,20,412.66,482.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,22,405.7,476.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,24,404.63,480.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,4,420.14,482.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,6,427.25,494.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,8,425.72,492.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,10,423.15,488.27)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,12,418.85,494.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,14,408.46,476.11)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,16,414.78,482.17)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,18,415.66,483.52)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,20,412.86,486.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,22,404.95,481.75)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,24,405.12,477.42)\n"
     ]
    }
   ],
   "source": [
    "#try different number of units in each hidden layer\n",
    "num_hidden_unit= list()\n",
    "for  x in range(8, 34,2):\n",
    "    for y in range(4, 26,2):\n",
    "        num_hidden_unit.append((x,y))\n",
    "\n",
    "rmse_for_each_num_hidden = list()\n",
    "for a, b in num_hidden_unit:\n",
    "    SVD_full_lasso_NN_model = build_full_NN(17, a, b)\n",
    "    SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "    train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "    test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "\n",
    "    print(f\"(first_layer, second_layer, train rmse, test rmse)=({a},{b},{round(train_rms, 2)},{round(test_rms, 2)})\")\n",
    "    rmse_for_each_num_hidden.append((a,b,train_rms,test_rms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 20, 419.724642160167, 460.7601075387045)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_for_each_num_hidden, key = lambda t: t[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'second_layer_nodes')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert list to dict\n",
    "rmse_dict = dict()\n",
    "for first_layer, second_layer, train_rmse, test_rmse in rmse_for_each_num_hidden:\n",
    "    rmse_dict[(first_layer, second_layer)] = test_rmse\n",
    "    \n",
    "plt.figure(figsize=(6, 4))\n",
    "# you should have a dictionary here.\n",
    "a3 = np.array([[rmse_dict[(first_layer, second_layer)] for first_layer in range(8, 34,2)] for second_layer in range(4, 26,2)])\n",
    "plt.title('hidden layer size')\n",
    "plt.imshow(a3, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=range(0, 13), labels=range(8, 34,2))\n",
    "plt.xlabel(\"first_layer_nodes\")\n",
    "plt.yticks(ticks=range(0, 11), labels=range(4, 26,2))\n",
    "plt.ylabel(\"second_layer_nodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(428.53,491.46)\n"
     ]
    }
   ],
   "source": [
    "''' Plot loss-iteration for (26, 24) '''\n",
    "SVD_full_lasso_NN_model = build_full_NN(17,8, 20)\n",
    "SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_lasso_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_lasso_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat on using top 5/4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEGCAYAAAD2TVeiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2P0lEQVR4nO3deXyV1Z348c83CyQhIZCFRQKEVQEXNgFrXZFF21Gx6tBN2vFXrEOd2l06M6I4ndEu6o+Zn7RY+YlaRxmslZ/VCq60ikBA9kWCbBcQAgkIIQSSfH9/nHPJTbgJSczNcxO+79fred3nnuc5zz33Br+e85zznCOqijHGmJoSgi6AMcbEIwuOxhgThQVHY4yJwoKjMcZEYcHRGGOiSAq6APEiJydH8/Pzgy6GMaYFrVy58qCq5kY7ZsHRy8/Pp6CgIOhiGGNakIjsrOuYNauNMSYKC47GGBOFBUdjjInC7jka04qdOnWKUCjEiRMngi5KXEtJSSEvL4/k5OQG57HgaEwrFgqFyMjIID8/HxEJujhxSVU5dOgQoVCIPn36NDifNauNacVOnDhBdna2BcZ6iAjZ2dmNrl1bcDSmlbPAeHZN+Y0sODbRa6/B0aNBl8IYEysxDY4iskNE1onIahEp8GkPiMgen7ZaRG6IOH+6iBSKyBYRmRCRPsJfp1BEZon/34CItBeRF336MhHJj8gzRUS2+m1Kc36vXbvgS1+Cbt3g3nth377mvLoxrcfhw4d54oknGp3vhhtu4PDhw/Wec//99/Pmm282sWTNQFVjtgE7gJxaaQ8AP45y7mBgDdAe6ANsAxL9seXAZYAArwPX+/R/BH7r9ycDL/r9LOAT/9rZ73eur6wjRozQhqqqUn3/fdU77lBNTFTNylJ9550GZzem2WzcuDHQz9++fbsOGTLkjPSKiooASlO/aL8VUKB1xIR4albfBLygquWquh0oBEaJSHego6ou9V/mGeDmiDzz/P4CYKyvVU4AFqtqsaqWAIuBic1VUBH4whdg3jzYsAG6dIG/+zvYs6e5PsGY1uG+++5j27ZtDB06lEsvvZRrrrmGr33ta1x00UUA3HzzzYwYMYIhQ4YwZ86c0/ny8/M5ePAgO3bsYNCgQXznO99hyJAhjB8/nrKyMgC+9a1vsWDBgtPnz5gxg+HDh3PRRRexefNmAIqKihg3bhzDhw/nrrvuonfv3hw8eLBZvlusg6MCi0RkpYhMjUj/noisFZG5ItLZp/UAdkecE/JpPfx+7fQaeVS1AjgCZNdzrRpEZKqIFIhIQVFRUZO+4Pnnw4cfwrJl0OOMTzCmZV199ZlbuNV7/Hj0408/7Y4fPHjmsbN5+OGH6devH6tXr+ZXv/oVy5cv5xe/+AUbN24EYO7cuaxcuZKCggJmzZrFoUOHzrjG1q1bmTZtGhs2bKBTp0689NJLUT8rJyeHVatWcffdd/PrX/8agAcffJBrr72WVatWMWnSJHbt2tWAX6lhYh0cL1fV4cD1wDQRuRKYDfQDhgL7gN/4c6N1J2k96U3NU52gOkdVR6rqyNzcqBNzNEhmJgwe7Pb/+tcmX8aYVm/UqFE1xhLOmjWLSy65hDFjxrB79262bt16Rp4+ffowdOhQAEaMGMGOHTuiXvuWW24545y//e1vTJ48GYCJEyfSuXPnqHmbIqaDwFV1r389ICIvA6NUdUn4uIg8Cbzq34aAnhHZ84C9Pj0vSnpknpCIJAGZQLFPv7pWnneb5UvVY8ECuO02WLMGLr441p9mzJnefbfuY2lp9R/Pyan/eEN06NAhoizv8uabb7J06VLS0tK4+uqro441bN++/en9xMTE083qus5LTEykoqICINxfERMxqzmKSAcRyQjvA+OB9f4eYtgkYL3fXwhM9j3QfYABwHJV3QccFZEx/n7iHcArEXnCPdG3Am/7+5JvAONFpLNvto/3aTF1zTWQklLdjDGmrcvIyOBoHWPajhw5QufOnUlLS2Pz5s18+OGHzf75X/ziF5k/fz4AixYtoqSkpNmuHcuaY1fgZT/qJgl4XlX/IiLPishQXDN3B3AXgKpuEJH5wEagApimqpX+WncDTwOpuN7q1336U8CzIlKIqzFO9tcqFpGHgBX+vJmqWhy7r+pkZ8PkyfDcc/DII665bUxblp2dzeWXX86FF15IamoqXbt2PX1s4sSJ/Pa3v+Xiiy/m/PPPZ8yYMc3++TNmzOCrX/0qL774IldddRXdu3cnIyOjWa4tsayWtiYjR47U5pjsdsUKGDUKZs+G7363GQpmTD02bdrEoEGDgi5GYMrLy0lMTCQpKYmlS5dy9913s3r16qjnRvutRGSlqo6Mdr5NPNHMLr0U+vaFN96w4GhMrO3atYvbb7+dqqoq2rVrx5NPPtls17bgGAOvvgq9ewddCmPavgEDBvDRRx/F5NoWHGPgHG7lGNNmxNMTMm2GKjz4IMydG3RJjDFNZcExBkTg9dfh978PuiTGmKay4Bgj113nHik8fjzokhhjmsKCY4yMGAFVVbB+/dnPNaa1auqUZQCPP/44x+O49mDBMUYuucS9rl0bbDmMiaW2HByttzpG8vPdFsd/e2M+t8gpy8aNG0eXLl2YP38+5eXlTJo0iQcffJDS0lJuv/12QqEQlZWV/Ou//iv79+9n7969XHPNNeTk5PDOO+8E/VXOYMExRhISYPv2oEthzikr74WS1c17zc5DYcTjdR5++OGHWb9+PatXr2bRokUsWLCA5cuXo6rceOONLFmyhKKiIs477zz+/Oc/A+6Z68zMTB599FHeeecdcnJymrfMzcSa1caYZrFo0SIWLVrEsGHDGD58OJs3b2br1q1cdNFFvPnmm/zsZz/jr3/9K5mtZNIBqznG0FtvwQ9+4J6Y6dUr6NKYNq+eGl5LUFWmT5/OXXfddcaxlStX8tprrzF9+nTGjx/P/fffH0AJG8dqjjGUmgrr1rn5HY1piyKnLJswYQJz587l2LFjAOzZs4cDBw6wd+9e0tLS+MY3vsGPf/xjVq1adUbeeGQ1xxjyy2iwZo1bY8aYtiZyyrLrr7+er33ta1x22WUApKen89xzz1FYWMhPfvITEhISSE5OZvbs2QBMnTqV66+/nu7du8dlh4xNWeY115RltfXuDVdeCc8+2+yXNuacn7KsMRo7ZZk1q2Osf38oLAy6FMaYxoppcBSRHSKyTkRWi0iBT8sSkcUistW/do44f7qIFIrIFhGZEJE+wl+nUERm+eUS8EsqvOjTl4lIfkSeKf4ztorIFAIybhwMGxbUpxtjmqolao7XqOrQiKrrfcBbqjoAeMu/R0QG45Y5GIJbY/oJEUn0eWYDU3Hrygygeg3qO4ESVe0PPAY84q+VBcwARgOjgBmRQfhzK1oKpTsbdOp999maMia27NbY2TXlNwqiWX0TMM/vzwNujkh/QVXLVXU7UAiM8gtydVTVpX7xrGdq5QlfawEw1tcqJwCLVbVYVUuAxVQH1M9vxV3wSj68dS0caNharPbv18RCSkoKhw4dsgBZD1Xl0KFDpKSkNCpfrHurFVgkIgr8TlXnAF39ioKo6j4R6eLP7QFELk8W8mmn/H7t9HCe3f5aFSJyBMiOTI+S5zQRmYqrkdKrMQMRr1wIO56Dwt/Bm1dCv+/ApU9Awpk/59atMHo0/Pa3cPvtDf8IYxoiLy+PUChEUVFR0EWJaykpKeTl5Z39xAixDo6Xq+peHwAXi8jmes6VKGlaT3pT81QnuGA9B1xvdT1lqyk9Hy78F7jgh7DuAdj0K6gsgzFPQ0JijVO7d4eSEti2rcFXN6bBkpOT6dOnT9DFaJNi2qxW1b3+9QDwMu7+3/7w2tX+9YA/PQT0jMieB+z16XlR0mvkEZEkIBO3RGtd12peSWkw7JdwyS9cTXLzb844JT0dunWzHmtjWpuYBUcR6SAiGeF9YDywHlgIhHuPpwCv+P2FwGTfA90H1/Gy3DfBj4rIGH8/8Y5aecLXuhV429+XfAMYLyKdfUfMeJ8WG0N+Dj1uhPUPQdm+Mw7bcB5jWp9Y1hy7An8TkTXAcuDPqvoX4GFgnIhsBcb596jqBmA+sBH4CzBNVSv9te4Gfo/rpNkGvO7TnwKyRaQQ+CG+51tVi4GHgBV+m+nTYmf4o1B1Elbfd8ahfv2sWW1Ma2NPyHjN8oTMqh/Blsfh5j2Q2u108oIFUFAA//Efbn0ZY0x8sCdkWkq/74BWwY7nayTfeis8/LAFRmNaEwuOzSnzAsgaCTvOfJC6tNRmBTemNbHg2Nz6fNPNxny4emWt7dtdr/X8+cEVyxjTOBYcm1vvySAJsGvB6aTu3d3r7t115DHGxB0Ljs0tpQt0GgoH3qtOSoHcXAiF6s5mjIkvFhxjocuVcOhDqCw/nZSXZ8HRmNbEgmMsdLkKKk9AcfXQoJ49rVltTGtiyyTEQu4X3euB9yD3cgC+9S04eDC4IhljGseCYyyk5EDmhXBgiXu0EJg0KeAyGWMaxZrVsdLlSih6H6rcE5Dl5bBlixvvaIyJfxYcYyV7NFQcg6NbAfjgA7jgAli2LOByGWMaxIJjrHS+xL2WrAZchwxYj7UxrYUFx1jpOAgSkuHwagB6+HnIrcfamNbBgmOsJLaDzCFQsgaA1FTIzraaozGthQXHWOo89HSzGlztcc+ewEpjjGkEG8oTS50ugU+ehrJPIbUbM2dCRkbQhTLGNIQFx1jqPNS9lqyB1G7cdFOgpTHGNELMm9UikigiH4nIq/79AyKyR0RW++2GiHOni0ihiGwRkQkR6SNEZJ0/NsuvJYNfb+ZFn75MRPIj8kwRka1+m0IQwj3WvlPm00/hrbegqiqQ0hhjGqEl7jl+H9hUK+0xVR3qt9cARGQwMBkYAkwEnhCR8Dqns3HrSw/w20SffidQoqr9gceAR/y1soAZwGjciocz/EJbLatdZ0jtAUfc158/H667Dopju5qNMaYZxDQ4ikge8CXc4lhncxPwgqqWq+p23GJao/zyrR1VdalfWfAZ4OaIPPP8/gJgrK9VTgAWq2qxqpYAi6kOqC0roz8cc0sPdvPLynz6aSAlMcY0Qqxrjo8DPwVqNyS/JyJrRWRuRI2uBxA5CjDk03r4/drpNfKoagVwBMiu51o1iMhUESkQkYKioqLGf7uGyOgPR11wDE96u+/M1VuNMXEmlutWfxk4oKorax2aDfQDhgL7gN+Es0S5jNaT3tQ81Qmqc1R1pKqOzM3NjZKlGaT3gxP74dSx0zVHC47GxL9Y1hwvB24UkR3AC8C1IvKcqu5X1UpVrQKexN0TBFe76xmRPw/Y69PzoqTXyCMiSUAmUFzPtVpeRn/3emzb6ZqjNauNiX8xC46qOl1V81Q1H9fR8raqfsPfQwybBIRXoloITPY90H1wHS/LVXUfcFRExvj7iXcAr0TkCfdE3+o/Q4E3gPEi0tk328f7tJaX7oPj0ULS0+FPf4LbbgukJMaYRghinOMvRWQorpm7A7gLQFU3iMh8YCNQAUxT1Uqf527gaSAVeN1vAE8Bz4pIIa7GONlfq1hEHgJW+PNmqmowfcQZ/dyr75SxsY7GtA7iKlpm5MiRWlBQcPYTm+KPXaHHjTD6SZYvd0N5JgbTd26MiSAiK1V1ZLRj9oRMS0jvB8e2AfDrX8PatbB5c8BlMsbUyyaeaAnp1cN5unWzDhljWgMLji0hoz8c3w0VZXTvDkeOQFlZ0IUyxtTHgmNLSO/rXkt32lMyxrQSFhxbQofe7rV0pz0lY0wrYR0yLSEcHI/v4rLLYMUKGDQo2CIZY+pnwbElpJ4HkgilO8nsDyOjDhwwxsQTa1a3hIQkN3VZ6U5U4fe/h/ffD7pQxpj6WHBsKR16Q+lOROBHP3JzOxpj4pcFx5bigyNAly5w4EDA5THG1MuCY0vp0AvK9kBVhQVHY1oBC44tpUNv0Eoo20uXLhCruXWNMc3DgmNLSase62g1R2PinwXHlhIxEHzmTPjoo2CLY4ypn41zbCkd/MTkx3fRtU+wRTHGnJ3VHFtKUgdonwOlOykshAcfhL3BLNxgjGmAmAdHEUkUkY9E5FX/PktEFovIVv/aOeLc6SJSKCJbRGRCRPoIEVnnj83yyyXgl1R40acvE5H8iDxT/GdsFZEpxIO0XlC6m9274YEH4OOPgy6QMaYuLVFz/D6wKeL9fcBbqjoAeMu/R0QG45Y5GIJbY/oJEUn0eWYDU3Hrygygeg3qO4ESVe0PPAY84q+VBcwARuMW8JoRGYQDk5YHZSHCCx1ap4wx8SumwVFE8oAvAb+PSL4JmOf35wE3R6S/oKrlqrodKARG+QW5OqrqUr941jO18oSvtQAY62uVE4DFqlqsqiXAYqoDanDS8uB4iC5d3FsLjsbEr1jXHB8HfgpURaR19SsK4l99qKAHsDvivJBP6+H3a6fXyKOqFcARILuea9UgIlNFpEBECopaYuBhWh6cLCE7sxQRC47GxLOYBUcR+TJwQFVXNjRLlDStJ72peaoTVOeo6khVHZkbbuvGUppbfjuxfA85ORYcjYlnsRzKczlwo4jcAKQAHUXkOWC/iHRX1X2+yRwOESGgZ0T+PGCvT8+Lkh6ZJyQiSUAmbonWEHB1rTzvNt9XayIfHDke4uOPB9KxY7DFMcbULWY1R1Wdrqp5qpqP62h5W1W/ASwEwr3HU4BX/P5CYLLvge6D63hZ7pveR0VkjL+feEetPOFr3eo/Q4E3gPEi0tl3xIz3acFKrQ6OnTpBgg2kMiZuBTEI/GFgvojcCewCbgNQ1Q0iMh/YCFQA01S10ue5G3gaSAVe9xvAU8CzIlKIqzFO9tcqFpGHgBX+vJmqWhzrL3ZWaf62Z1mIF1+Edevg3/4t2CIZY6ITV9EyI0eO1IKCgth/0IJs6P333PPMEzz3HJSUxP4jjTHRichKVY06N7817FpaxHCew4fh5MmgC2SMicaCY0urNdbRpi4zJj5ZcGxpNhDcmFbBgmNLS82D8iK65p6gfXvXtDbGxB+bsqyl+bGOl12yl7Kyvki04erGmMBZzbGl+eAoZSELjMbEsQYFRxHpICIJfn+giNwoIsmxLVobFfGUzF13wdNPB1oaY0wdGlpzXAKkiEgP3DRj38YNyjaNFREcX3sNliwJtjjGmOgaGhxFVY8DtwD/qaqTgMGxK1YblpwByR1P91hbb7Ux8anBwVFELgO+DvzZp1lnTlNFDOex4GhMfGpocLwXmA687J+B7gu8E7NStXWpFhyNiXcNqv2p6nvAewC+Y+agqv5TLAvWpqXlwZF19O4NGRlBF8YYE01De6ufF5GOItIBN2vOFhH5SWyL1oal5UHZp8x84BTr1gVdGGNMNA1tVg9W1c9wa7e8BvQCvhmrQrV5aXmAQtm+oEtijKlDQ4Njsh/XeDPwiqqeIsqyA6aB/HCej9eEGDcO1q4NuDzGmDM0NDj+DtgBdACWiEhv4LNYFarNO72WTIg334QdO4ItjjHmTA3tkJkFzIpI2iki18SmSOcAHxyzUtyiitZjbUz8aWiHTKaIPBpexlREfoOrRdaXJ0VElovIGhHZICIP+vQHRGSPiKz22w0ReaaLSKGIbBGRCRHpI0RknT82y68lg19v5kWfvkxE8iPyTBGRrX6bQjxJ7gSJaWQkuOBoczoaE38a2qyeCxwFbvfbZ8D/PUuecuBaVb0EGApMFJEx/thjqjrUb68BiMhg3BowQ4CJwBMikujPnw1MxS26NcAfB7gTKFHV/sBjwCP+WlnADGA0MAqY4Rfaig8ikJZH0qkQ6elWczQmHjU0OPZT1Rmq+onfHgT61pdBnWP+bbLf6uvEuQl4QVXLVXU7UAiM8su3dlTVpX5lwWdwHUPhPPP8/gJgrK9VTgAWq2qxqpYAi6kOqPHBPyVz2WXQOX7CtjHGa2hwLBORL4bfiMjlQNnZMolIooisxq1NvVhVl/lD3xORtSIyN6JG1wPYHZE95NN6+P3a6TXyqGoFcATIrudatcs3NXyroKil27Y+OC5aBPff37IfbYw5u4YGx+8C/0dEdojIDuC/gLvOlklVK1V1KJCHqwVeiGsi98M1tfcBv/GnR5vdUOtJb2qeyPLNUdWRqjoyNze3nm8SA2l5ULYXqirPfq4xpsU1KDiq6hp/7/Bi4GJVHQZc29APUdXDwLvARFXd74NmFfAk7p4guNpdz4hsecBen54XJb1GHhFJAjJx61fXda34kZYHWskTj+3nqquCLowxprZGzQSuqp/5J2UAfljfuSKSKyKd/H4qcB2w2d9DDJsErPf7C4HJvge6D67jZbmq7gOOisgYfz/xDuCViDzhnuhbgbf9fck3gPEi0tk328f7tPiRWj0j+AcfQFVVwOUxxtTweaYdO9sk/92Beb7HOQGYr6qvisizIjIU18zdgW+e+9l+5uOe3a4ApqlquM15N25y3VTgdb8BPAU8KyKFuBrjZH+tYhF5CFjhz5upqsWf47s2Pz/WMS87REXFKA4fhqysYItkjKn2eYJjvY8PqupaYFiU9DqfyVbVXwC/iJJeAFwYJf0EcFsd15qLG4IUn3xw7J5ZPRDcgqMx8aPe4CgiR4keBAVXizNN1T4HEtqRE/GUzAUXBFwmY8xp9QZHVbXZBmPFDwTPahdi7Fho3z7oAhljItlSB0FKy6OjusknjDHxxdatDpJfLsEYE38sOAYpLQ/K9jBmdBU/sXnVjYkrFhyDlJYHVSdJqjxoczoaE2csOAbJD+cZ1DtkM/MYE2csOAbJB8f+PULs3x9wWYwxNVhwDJIPjn27hthna20ZE1csOAapfReQJC7sG2LSJKi0CXqMiRs2zjFICYmQeh6DuoR4+umgC2OMiWQ1x6Cl5UFZCFWbmceYeGLBMWhpeZw8HCItDRYsCLowxpgwC45BS8sj+VSIEyeUvfE1Ha8x5zQLjkFLy0OqyujSqcR6rI2JIxYcg+aH8wwdaMN5jIknMQuOIpIiIstFZI2IbBCRB316logsFpGt/rVzRJ7pIlIoIltEZEJE+ggRWeePzfLLJeCXVHjRpy8TkfyIPFP8Z2wVkSnEK79cwuB8C47GxJNY1hzLgWv9wlxDgYkiMga4D3hLVQcAb/n3iMhg3DIHQ3BrTD/hl1gAt2LhVNy6MgOoXoP6TqBEVfsDjwGP+GtlATOA0bgFvGZEBuG44muON14X4sYbAy6LMea0mAVHdY75t8l+U+AmYJ5Pnwfc7PdvAl5Q1XJV3Q4U4pZz7Q50VNWlfvGsZ2rlCV9rATDW1yon4NbJLlbVEmAx1QE1vqR2A0ngmtEh7rkn6MIYY8Jies9RRBJFZDVwABeslgFd/YqC+Ncu/vQewO6I7CGf1sPv106vkUdVK4AjQHY916pdvqkiUiAiBUVFRZ/jm34OCcmQ0g0tDXHokD0lY0y8iGlw9OtTD8WtGz1KRM5YJCtCtNUMtZ70puaJLN8cVR2pqiNzc3PrKVqMpeWxtzBETg7s3n32040xsdcivdWqehh4F9e03R9eu9q/hifrCgE9I7LlAXt9el6U9Bp5RCQJyMQt0VrXteJTWh6ZyS4qWqeMMfEhlr3VuSLSye+nAtcBm4GFQLj3eArwit9fCEz2PdB9cB0vy33T+6iIjPH3E++olSd8rVuBt/19yTeA8SLS2XfEjPdp8Sm9P2n6CQlSaQPBjYkTsZx4ojswz/c4JwDzVfVVEVkKzBeRO4Fd+HWnVXWDiMwHNgIVwDRVDd+Buxt4Grcc7Ot+A3gKeFZECnE1xsn+WsUi8hCwwp83U1WLY/hdP5+OA0nQk/TO2Uko1Dfo0hhjiGFwVNW1wLAo6YeAsXXk+QXwiyjpBcAZ9ytV9QQ+uEY5NheY27hSByRjIAAX53/Mzp0WHI2JBzZlWTzoeD4A9/6vj6noG58jjow511hwjAftcyE5k6uHbYFLgy6MMQbs2er4IAIZA6ko+ZjVq4MujDEGLDjGj44DKf30Y4YNgyNHgi6MMcaCY7zIOJ/MpF2ktjvOzp1BF8YYY8ExXnR0Pdb9uxayY0ewRTHGWHCMH344z/ndt1hwNCYOWHCMFx0vQCWJMQNXWnA0Jg7YUJ54kZSKZA3nm9d/wJ5BQRfGGGM1x3iSczldElcw7OKTQZfEmHOeBcd4kvsFqDzBklc+Qs+YYM0Y05IsOMaTnC8A8PKTH7B/f8BlMeYcZ8ExnqSdR1lCPl8Y+AGbNgVdGGPObRYc40xVzuVccf5f2bSpKuiiGHNOs+AYZ9L6TqBbp/0c37U86KIYc06z4BhnJO/vOFWZTE9eCrooxpzTYrlMQk8ReUdENonIBhH5vk9/QET2iMhqv90QkWe6iBSKyBYRmRCRPkJE1vljs/xyCfglFV706ctEJD8izxQR2eq3KbQW7TpxvON13HLpS1iXtTHBiWXNsQL4kaoOAsYA00RksD/2mKoO9dtrAP7YZGAIbiGuJ/wSCwCzgam4dWUGUL0G9Z1Aiar2Bx4DHvHXygJmAKOBUcAMv5ZMq5B54VdILt8OJR8FXRRjzlkxC46quk9VV/n9o8AmoqwdHeEm4AVVLVfV7UAhbjnX7kBHVV3qF896Brg5Is88v78AGOtrlRNw62QXq2oJsJjqgBr3DqbcRKUm8dmqOUEXxZhzVovcc/TN3WHAMp/0PRFZKyJzI2p0PYDIVZtDPq2H36+dXiOPqlYAR4Dseq7VKpQcz2H24rtI3/97OLIx6OIYc06KeXAUkXTgJeBeVf0M10TuBwwF9gG/CZ8aJbvWk97UPJFlmyoiBSJSUFRUVN/XaFF9+8IvX5tBeWU6rPohVFWePZMxplnFNDiKSDIuMP5BVf8IoKr7VbVSVauAJ3H3BMHV7npGZM8D9vr0vCjpNfKISBKQiVuita5r1aCqc1R1pKqOzM3N/TxftVklJkKfQbk88beZsO8NeGcCHNtx9oyqUPYpHNkMx0NnP98YU6eYzcrj7/09BWxS1Ucj0rur6j7/dhKw3u8vBJ4XkUeB83AdL8tVtVJEjorIGFyz/A7gPyPyTAGWArcCb6uqisgbwL9HNNnHA9Nj9V1j4QtfgOm/+Sfu+UE67dZOg4V9IHs0dLkS2mXBqSOQ0M69HvsEjm2DY9uhsqz6Ip0ugqR0qDgO6fmQmAaVJ6CqHJI7QXpfqCiFyuOgFVD8EZQfhIz+kDEAUs+DqlOQ0Q86D3Pnts+G9P6QkFhX0Y1pE2I5ZdnlwDeBdSKy2qf9HPiqiAzFNXN3AHcBqOoGEZkPbMT1dE9T1XB78m7gaSAVeN1v4ILvsyJSiKsxTvbXKhaRh4AV/ryZqlock28ZI5ddBpWVsL7sHxj+5bGw43kILYQtj7uAJUkuoCWmueCVMRC6T3QBr11nV4Pc+5q7WLtsOFoIVSchMQUS2sORDbDzeUjq4K4hApkXQeYgOLoNdv0PnCzG3aGodUciMRUyBwMJULrdnZPSBTpdAt3GQtYIOHUUTh2G0p1QXOACeXo/t3W62AVgiXb3w5j4IGpj6QAYOXKkFhQUBF2M006cgIoKSE+vdaCyHLQSktKqx0E2NchoFUg9d1aqKtzxIxvdlpwBJ/bD4XVuQ12wAyjbC8Ur3WttKV3cZ5UfrE5LznRbYooL0NmjIC0Pju+G3CvhvOtdLTclFxKSofIkJCTVX15jGklEVqrqyGjHbLLbOJWSUseBxPbV+5+35nW2QJPg/3l0utBtZ6MKJavh6FZo18k13VO7u6AnAiePwLFCKF7lzqs87gJgebGrGVcchaQMKIwYwpSY4pr3pTtc7TNjAHQbBx16u2B7ZCO0z4GB34PMIVYbNc3Gao5evNUcAf74R3j+efif/zkH/puvqqhu9u9/xwXPpDT4bKurjWb0d/dKS1bDgSXuXMTVXMv2uHut7bIguSOcOAC5X4Set7jA2j7HbSk5LmC3+R/TNJTVHFupkhJ46SVYuxYuuSTo0sRYQlJ1TbXbWLfVpaLMBcPkDNfkLj8EO19wTf2KY665vudVWPHdM/N2HAS9bnM11sRUt+pjxkB3q+Lox+5+acdBFkCNBcd4duONkJAACxacA8GxMZJS3RbWPhsGTqt5zsj/dJ1B5Qert7J9sPtlWD/TNdGrThFl+KtrsmePdvdCJQFSurkttTukdnOdYajrgIosh2lTrFntxWOzGuCaa2D/fthoD8o0n4pS10NfVe6GQX22BRDX61/0Pux/Gw4VuKa7VkL5AdehVFtCe1fzbJflAnS7LNd8zxruaqAp3dw5VeXu1kBShuucslpp3LBmdSv2la/APffApk0wyFYlbB5JHdxrYoobkpQ5uPpYp4tgQK3meFWlq3me+NTVPlEXOA/81Y0vLT/kAuzJYnde1am6PzsxzY057dDH1VDb57rOrvOury6XiQsWHOPcLbfAyy9DaWnQJTmHJSRCale3dY64v5F305nnVp1yg+mPrHcdQ1UnXRM+tbsb+1m63Q3WL90OBz+AkyX+M9pBWk93H7Sq3I0Fzb7U1TxLPnK3CMJpnYdBeh8LpjFmzWovXpvVpo2rqoCiv7kB+8dDrqNJEuHQcjfmE1ztMr2vC7gVEf+XbJ8Dab1cj3xiiguq6f0h8wI38P/YJ+6WQFpPV0tN7+8G+UuCu01weJ0L2ElpbqiUJEHWSEg7L5CfIgjWrG4DDhyALVvgiiuCLolpVglJ0PVqt0VSdYGwqtzdyxRxzfvPNsPhtS6Yle502/HdvoaaBJ8udj3xp6/fzg978pI7ufuj5UVw6rPoZUo9z91eSOnqAmZyR+hyFegpV9Pteq0bWtXGWXBsJb71LfjoI9i6NcpTM6btEYHkdCDij52QCJ2GuK0uVRWu86f8EHTo5QJreRGU7nID5g9+UD3cKecyFwArjrqaZWU5HFoBxSvcPdQjm4AqN0h/y+M1PyehvWvW197ad/HDo85316466Qbud+jlHg5ISHYPBSR3jMGP1rysWe3Fe7P6/ffhyivhq1+FZ5+1Dk/TgirL3fPx4efw9y1ytdWKUqgsda+njrn9sk9dc14r6r9mUgak9XCBMjX82t0Fz6SOrmbaPtudl5zugnEM/tFbs7oNuPxymDkT/uVfYPRo14NtTItIbA+5l1e/7ziw/vOrTrlOp/KD7v7pkQ1wfA90PN8NjToeck81HQ+57bO33CiA0/PMRCFJLjgntHMBNDHFTbDSrrO7v5rS1d1WOFEEg34InYd+7q9twbEVmT4dli+H738f+vSBL3856BIZE0VCsg+gPojmjD57nvBwKa2Ek4fczFCnDrsOo4qjrmZaccwFXj3lnpI6ddg1+Ut3uhqrVrqJSvp8o1m+hgXHViQhAV58ER58EK6+OujSGNOMwsOlwPWWd7oo2PJg61a3Oikp8B//4Tpljh514yCffRbKy4MumTFtiwXHVmz9evfkzB13QK9e8POfu/fGmM/PgmMrdtll7pnrRYtg1Ch45BEYPBg++cQdP3IEqqI8EmyMObuYBUcR6Ski74jIJhHZICLf9+lZIrJYRLb6184ReaaLSKGIbBGRCRHpI0RknT82y69Pg4i0F5EXffoyvwRsOM8U/xlbRWRKrL5n0ERg3Dj4f/8PQiH43e9cZw3AP/4j5Oa6pvesWW7qMwuWxjRMLGuOFcCPVHUQMAaYJiKDgfuAt1R1APCWf48/NhkYAkwEnhCR8CpOs4GpuEW3BvjjAHcCJaraH3gMeMRfKwuYAYzGrW44IzIIt1Xdu8PUqdXDwW65BW6+GdascT3cl1xSsyNn5Ur4rI6HJIw518Wst9qvMLjP7x8VkU1AD+Am4Gp/2jzgXeBnPv0FVS0HtvtFs0aJyA6go6ouBRCRZ4CbcYts3QQ84K+1APgvX6ucACwOL6olIotxAfW/Y/V949FXvuI2gF274L33qgNnZaWbDu3YMRgyBMaMcc30a66prnkacy5rkXuOvrk7DLe0atfw0qz+tYs/rQewOyJbyKf18Pu102vkUdUK4AiQXc+1apdrqogUiEhBUVHR5/iG8a9XL/jmN+EbEUPAXnoJHngA8vLchLp33glz57pjx47BjBluiYZNm+BUPbNwGdMWxXyco4ikAy8B96rqZ1L3I0DRDmg96U3NU52gOgeYA+7xwboK1hYlJrp7lePGufdVVfDxx9DBz4K1YQP8279V36NMToYLLoDHHoOxY11nT2kpnHfuTOBizjExDY4ikowLjH9Q1T/65P0i0l1V94lId+CATw8BPSOy5wF7fXpelPTIPCERSQIycetXh6huuofzvNtMX6tNSkhwwS9s9GhXe9y82QXK9evda6dO7vhf/gKTJ7sm+fDh0L8/dOvmmvHZ2YF8BWOaVcwmnvD3/uYBxap6b0T6r4BDqvqwiNwHZKnqT0VkCPA8rgPlPFxnzQBVrRSRFcA9uGb5a8B/quprIjINuEhVvysik4FbVPV23yGzEhjuP3YVMCJ8DzKaeJ94It7s2uWe1nn7bdcLvtf/72r37upm+qJF7v5l377VW1aWTZph4kdQE09cDnwTWCciq33az4GHgfkiciewC7gNQFU3iMh8YCOup3ua6ukn0e8GngZScR0xr/v0p4BnfedNMa63G1UtFpGHgBX+vJn1BUbTeL16wU9+4jaAkyfh009dYARYtw5eecXNQxmWnAxlZa5J/9577ljv3pCf74YcWdA08cSmLPOs5hgbx47B9u1uYPrBg67TB1zP+IcfVp+Xng7XXusCKrhme2qqa6537+6a/cY0N5uyzAQmPR0uushtkf7yF9ixA3burA6eHSPmP73nHigsrL7G8OEwaRLce69LW7jQdR5VVblOocGDreZpmpcFRxOIzEw3KL2u9bgXLXLBsbDQdQQVFLj7nOBWELjtNteUD+vVC376U5g2zU3CMW2a61Xv18813bvYiqimkSw4mrjUp4/bwkONalu1Cg4dcgFv0yZ4883qmueWLW4M51NPVZ+fmgrPPAO33uqOP/aYC6g9e7rXXr3c/dLk5Nh/N9M6WHA0rY6IG0IUdsUV7rHJsIsvdp09mza5Znu46X7++e74rl0ueB48WPO6b77papt//jPcf78b2nThha7WmZvrnh7KyHBNebsH2vZZcDRtUnKyC5IXX3zmsXHjoKgIjh93Q4927XKv4XNTUlxAXLIEnn++Ol9hoQuOjz7qgmfHju5+aEaGa7o/9ZQb4/nee262pHCttGtXV57Ona1p35pYcDTnrLQ0V5sM1yjDxo51G7ingA4edMG0p39EYcQIN+PRsWNuO3zYdShlZLjjf/oTPP54zWsmJMCJEy5I/vznsHSp64nPzHQdS1lZbnIQcDXdxERXW23fPkZf3pyVDeXxbCiPaS6nTrlgunu32w4cgKSk6qb/rFluAP22bW429+PHXeANdzjdcAO87kfypqS4Gufw4fDqqy7t8cfdbYIOHdyWlubuz958szu+dKmbWCR8rEMHV8uNHA1gnPqG8lhw9Cw4mqBUVblaZVqae//ee67T6OBBKClxNdNOneBXv3LHr7zSTUNXWuqCILip6N55x+0PHOjWN4/0pS9VB9eJE13A7NSpOsCOHu2Ca2UlzJ8PFRUuvU8fF7hTUtrmeuk2ztGYOJaQUB0YAa66ym11WbKkev/kSVfzDAdJgD/8wQXU0lJ3LHKCkMpK1/xfv97VWktL3a2Bb3/bBUcR+PrX3XCpSNOnw7//u7vuFVe4a4S39HT3nP3Eia7G/PjjbnRAbq7r1OrY0d17zc52teoTJ1yeeL//asHRmFasXTu3Rbr00rrPT0x009DVFg6uCQmulz8x0U2EvG0b7NsHI0dWn9e/vwushw+72eePHnXzgYKbremRR2oGa3BT4X37224I1pgx7t5rVpYLrkeOwOzZbtKSlSvhl790tdb09Ort6193nV7he8BpaW5LTY3dyAELjsYYEhOr9yM7qIYPr3ledja8/HLd1+nf3zXJw8/ab9niaq9Dh7rjPXq44Fdc7MapHj3qOqXCT1AdPlx9y+DYMXe8stLdSujdG/74R7egXKTUVLee+4UXNvXbR2f3HD2752hM/FF1gTYx0XVqbdwIy5bVvGVw/LibAKVLl7Nfrza752iMaZVEag5nGjzYbS3BxvkbY0wUFhyNMSYKC47GGBNFzIKjiMwVkQMisj4i7QER2SMiq/12Q8Sx6SJSKCJbRGRCRPoIEVnnj83yyy8gIu1F5EWfvsyvcBjOM0VEtvptSqy+ozGm7YplzfFp3FrRtT2mqkP99hqAiAzGLXEwxOd5QkTCgwtmA1OBAX4LX/NOoERV+wOPAY/4a2UBM4DRuPVoZohI5+b/esaYtixmwVFVl+DWdWmIm4AXVLVcVbcDhcAovzphR1Vdqm7M0TPAzRF55vn9BcBYX6ucACxW1WJVLQEWEz1IG2NMnYK45/g9EVnrm93hGl0PYHfEOSGf1sPv106vkUdVK4AjQHY91zLGmAZr6eA4G+gHDAX2Ab/x6dGestR60puapwYRmSoiBSJSUFRUVE+xjTHnmhYdBK6q+8P7IvIk4OcJIQT0jDg1D9jr0/OipEfmCYlIEpCJa8aHgKtr5Xm3jvLMAeb48hSJyM5GfJ0c4OBZzwpGvJYtXssFVramiNdyQcPL1rvOI6oasw3IB9ZHvO8esf8D3H1GcB0xa4D2QB/gEyDRH1sBjMHVCF8HbvDp04Df+v3JwHy/nwVsBzr7bTuQFYPvVhDL364tli1ey2Vla1vlaq6yxazmKCL/javB5YhICNeDfLWIDMU1c3cAdwGo6gYRmQ9sBCqAaaoantfjblzPdyouOPppQHkKeFZECnE1xsn+WsUi8hAuqALMVNWGdgwZYwxgE080mYgUaB0PrActXssWr+UCK1tTxGu5oHnKZk/INN2coAtQj3gtW7yWC6xsTRGv5YJmKJvVHI0xJgqrORpjTBQWHI0xJgoLjo0kIhP95BiFInJfwGXpKSLviMgmEdkgIt/36XVO8NHC5dvhJw1ZLSIFPi1LRBb7SUEWt/Rz7yJyfsTvslpEPhORe4P6zeqYoKXO36iuCVpasGy/EpHN/im3l0Wkk0/PF5GyiN/vtwGUrdET29Qr6PFIrWkDEoFtQF+gHW5s5uAAy9MdGO73M4CPgcHAA8CP4+D32gHk1Er7JXCf378PeCTgv+enuIHAgfxmwJXAcGqOB476G/m/beR44G348cAtWLbxQJLffySibPmR5wX0u0X9Gzb1d7OaY+OMAgpV9RNVPQm8gJsAIxCquk9VV/n9o8Am4v858sgJQ+ZRPZFIEMYC21S1MU9GNSuNPkFLXb9R1AlaWrJsqrpI3VwGAB9S8wm2FlPH71aXJv1uFhwbJ24ntfDzWQ4DlvmkaBN8tDQFFonIShGZ6tO6quo+cMEdaMKySM1mMvDfEe/j4TeDun+jePv39w9UP5QB0EdEPhKR90TkioDK1JiJbeplwbFxGjypRUsSkXTgJeBeVf2Muif4aGmXq+pw4HpgmohcGVA5ziAi7YAbgfAqzvHym9Unbv79icg/455m+4NP2gf0UtVhwA+B50WkYwsXq7ET29TLgmPj1DVBRmBEJBkXGP+gqn8EN8GHqlaqahXwJDFsetVHVff61wPAy74c+/08nfjXA0GUDRewV6mfDCVefjOvrt8oLv79iZtd/8vA19Xf1PNN1kN+fyXuvt7AlixXPX/DJv1uFhwbZwUwQET6+JrHZGBhUIXxk/s+BWxS1Ucj0rtHnDYJWF87bwuUrYOIZIT3cTfy1+N+r/DSFVOAV1q6bN5XiWhSx8NvFqGu32ghMFncEiF9cDPjL2/JgonIROBnwI2qejwiPVf87P0i0teX7ZMWLltdf8Om/W4t1bvUVjbgBlyv8DbgnwMuyxdxzYO1wGq/3QA8C6zz6QuJmA2pBcvWF9dDuAbYEP6tcBMSvwVs9a/NPmNSA8qWBhwCMiPSAvnNcAF6H3AKV8O5s77fCPhn/29vC3B9AGUrxN2/C/97C8+M9RX/d14DrAL+LoCy1fk3bMrvZo8PGmNMFNasNsaYKCw4GmNMFBYcjTEmCguOxhgThQVHY4yJwoKjaXVE5Jh/zReRrzXztX9e6/0HzXl903pYcDStWT7QqOAYHqhcjxrBUVW/0MgymTbCgqNpzR4GrvBz9/1ARBL9fIMr/OQDdwGIyNV+3svncYOEEZE/+QkxNoQnxRCRh4FUf70/+LRwLVX8tdeLm6Py7yOu/a6ILPDzHP7BP7lkWrmYLc1qTAu4Dzd/35cBfJA7oqqXikh74H0RWeTPHQVcqG7KKoB/ULeMbyqwQkReUtX7ROR7qjo0ymfdgpvQ4BLcgvErRGSJPzYMt/b6XuB94HLgb839ZU3LspqjaUvGA3eIyGrc1G3ZuOdoAZZHBEaAfxKRNbg5CXtGnFeXLwL/rW5ig/3Ae8ClEdcOqZvwYDWuuW9aOas5mrZEgHtU9Y0aiSJXA6W13l8HXKaqx0XkXSClAdeuS3nEfiX231WbYDVH05odxS0PEfYGcLefxg0RGehnBKotEyjxgfECYEzEsVPh/LUsAf7e39fMxU3T36Iz4piWZf+HM63ZWqDCN4+fBv43rkm7yneKFBF9GYa/AN8VkbW4WVo+jDg2B1grIqtU9esR6S8Dl+FmnVHgp6r6qQ+upg2yWXmMMSYKa1YbY0wUFhyNMSYKC47GGBOFBUdjjInCgqMxxkRhwdEYY6Kw4GiMMVH8f/j7qIcfeRf1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(408.05,464.49)\n"
     ]
    }
   ],
   "source": [
    "#5 cols\n",
    "\n",
    "lasso_genomic_df_0 = genomic_df_0[[\"SMG_mutsig2.0_SFT2D1_cosmic\",\"Amp_8q24.21 \",\"Del_1p36.32 \",\"Del_10p11.23\",\"CN_1p_Amp\"]]\n",
    "\n",
    "#SVD\n",
    "# Perform SVD matrix factorization to extract features\n",
    "U, s, V = np.linalg.svd(lasso_genomic_df_0.to_numpy(), full_matrices=False)\n",
    "pd.DataFrame(U) # Select the top 5 features out of 595 cols in U\n",
    "\n",
    "\n",
    "SVD_lasso_genomic_X = pd.DataFrame(np.column_stack((genomic_df['tcga_participant_barcode'].values, U[:, :5])))\n",
    "SVD_lasso_genomic_X = SVD_lasso_genomic_X.rename(columns={0: 'tcga_participant_barcode'})\n",
    "\n",
    "\n",
    "#merge CLI and Genomic\n",
    "SVD_lasso_full_X = pd.merge(processed_CLIs_df, SVD_lasso_genomic_X, on='tcga_participant_barcode', how='inner')\n",
    "SVD_lasso_full_X.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1, inplace = True)\n",
    "\n",
    "#normalization\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(SVD_lasso_full_X)\n",
    "SVD_lasso_full_X = pd.DataFrame(zscore_scaler.transform(SVD_lasso_full_X), columns = SVD_lasso_full_X.columns)\n",
    "\n",
    "y = processed_CLIs_df[['Overall_Survival']]\n",
    "SVD_lasso_full_X_train, SVD_lasso_full_X_test, y_train, y_test = train_test_split(SVD_lasso_full_X, y, test_size=0.2,random_state =42)\n",
    "#NN\n",
    "sc = StandardScaler()\n",
    "SVD_lasso_full_X_train = sc.fit_transform(SVD_lasso_full_X_train)\n",
    "SVD_lasso_full_X_test = sc.transform(SVD_lasso_full_X_test)\n",
    "\n",
    "''' Plot loss-iteration for (14, 24) '''\n",
    "SVD_full_lasso_NN_model = build_full_NN(19,14, 24)\n",
    "SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_lasso_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_lasso_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(first_layer, second_layer, train rmse, test rmse)=(8,4,438.71,513.26)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,6,440.53,507.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,8,424.5,487.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,10,417.13,477.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,12,420.07,478.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,14,417.13,472.04)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,16,424.45,482.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,18,426.3,485.86)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,20,421.98,473.72)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,22,413.77,475.72)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,24,403.3,478.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,4,419.26,490.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,6,416.72,477.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,8,422.88,486.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,10,415.07,484.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,12,411.36,477.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,14,418.41,489.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,16,414.08,475.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,18,416.63,486.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,20,403.36,461.28)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,22,410.85,486.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,24,407.01,475.99)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,4,412.88,495.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,6,422.9,476.67)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,8,418.08,494.89)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,10,419.68,481.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,12,420.82,472.57)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,14,418.12,467.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,16,409.24,485.22)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,18,408.88,475.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,20,410.7,482.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,22,413.11,486.49)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,24,409.16,474.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,4,430.37,507.82)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,6,422.24,486.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,8,418.02,479.47)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,10,416.11,485.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,12,404.61,474.15)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,14,399.19,469.67)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,16,403.88,469.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,18,407.26,477.26)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,20,407.44,478.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,22,406.7,474.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,24,406.2,483.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,4,419.97,495.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,6,425.3,495.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,8,407.54,466.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,10,407.95,483.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,12,413.07,479.59)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,14,411.55,492.49)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,16,400.93,471.6)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,18,408.39,480.06)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,20,408.27,474.23)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,22,407.36,469.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,24,395.71,454.06)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,4,425.9,492.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,6,416.91,477.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,8,415.42,472.14)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,10,401.8,475.42)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,12,406.0,471.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,14,400.47,465.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,16,404.23,481.94)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,18,405.87,476.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,20,402.99,476.65)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,22,392.31,464.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,24,401.15,479.16)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,4,414.24,471.69)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,6,403.31,473.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,8,410.55,481.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,10,409.95,476.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,12,410.26,487.85)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,14,414.49,477.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,16,397.09,462.04)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,18,394.79,469.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,20,398.26,464.8)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,22,401.49,462.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,24,400.43,463.74)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,4,410.36,479.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,6,426.69,507.19)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,8,420.25,491.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,10,398.89,476.08)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,12,401.07,474.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,14,403.39,484.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,16,403.37,476.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,18,406.98,477.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,20,391.37,467.46)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,22,395.03,470.87)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,24,391.47,469.65)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,4,404.95,488.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,6,403.98,477.9)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,8,400.98,477.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,10,415.14,472.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,12,399.0,476.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,14,397.43,472.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,16,402.04,483.45)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,18,395.15,478.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,20,401.54,474.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,22,399.49,478.02)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,24,399.27,476.62)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,4,413.03,479.19)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,6,410.85,480.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,8,402.06,471.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,10,416.66,488.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,12,396.66,476.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,14,395.98,460.28)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,16,391.78,470.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,18,394.52,464.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,20,387.47,467.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,22,392.02,480.9)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,24,390.45,462.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,4,417.05,479.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,6,408.48,475.74)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,8,402.34,475.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,10,397.35,464.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,12,396.36,475.6)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,14,404.81,477.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,16,392.4,476.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,18,398.08,461.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,20,392.53,465.26)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,22,391.65,465.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,24,387.92,459.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,4,423.29,495.15)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,6,405.66,477.7)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,8,407.12,471.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,10,399.23,481.85)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,12,396.42,470.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,14,395.57,472.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,16,403.16,472.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,18,394.49,473.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,20,388.78,463.59)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,22,394.03,465.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,24,391.41,458.46)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,4,405.86,474.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,6,411.05,479.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,8,403.82,478.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,10,400.39,479.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,12,396.44,479.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,14,390.64,468.17)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,16,396.46,477.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,18,395.17,474.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,20,388.12,467.92)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,22,391.42,474.17)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,24,391.99,476.83)\n"
     ]
    }
   ],
   "source": [
    "#try different number of units in each hidden layer\n",
    "num_hidden_unit= list()\n",
    "for  x in range(8, 34,2):\n",
    "    for y in range(4, 26,2):\n",
    "        num_hidden_unit.append((x,y))\n",
    "\n",
    "rmse_for_each_num_hidden = list()\n",
    "for a, b in num_hidden_unit:\n",
    "    SVD_full_lasso_NN_model = build_full_NN(19, a, b)\n",
    "    SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "    train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "    test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "\n",
    "    print(f\"(first_layer, second_layer, train rmse, test rmse)=({a},{b},{round(train_rms, 2)},{round(test_rms, 2)})\")\n",
    "    rmse_for_each_num_hidden.append((a,b,train_rms,test_rms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 24, 395.7086762510138, 454.0622159178097)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_for_each_num_hidden, key = lambda t: t[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(405.98,480.44)\n"
     ]
    }
   ],
   "source": [
    "#4 cols\n",
    "\n",
    "lasso_genomic_df_0 = genomic_df_0[[\"SMG_mutsig2.0_SFT2D1_cosmic\",\"Amp_8q24.21 \",\"Del_1p36.32 \",\"Del_10p11.23\",\"CN_1p_Amp\"]]\n",
    "\n",
    "#SVD\n",
    "# Perform SVD matrix factorization to extract features\n",
    "U, s, V = np.linalg.svd(lasso_genomic_df_0.to_numpy(), full_matrices=False)\n",
    "pd.DataFrame(U) # Select the top 4 features out of 595 cols in U\n",
    "\n",
    "\n",
    "SVD_lasso_genomic_X = pd.DataFrame(np.column_stack((genomic_df['tcga_participant_barcode'].values, U[:, :4])))\n",
    "SVD_lasso_genomic_X = SVD_lasso_genomic_X.rename(columns={0: 'tcga_participant_barcode'})\n",
    "\n",
    "\n",
    "#merge CLI and Genomic\n",
    "SVD_lasso_full_X = pd.merge(processed_CLIs_df, SVD_lasso_genomic_X, on='tcga_participant_barcode', how='inner')\n",
    "SVD_lasso_full_X.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1, inplace = True)\n",
    "\n",
    "#normalization\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(SVD_lasso_full_X)\n",
    "SVD_lasso_full_X = pd.DataFrame(zscore_scaler.transform(SVD_lasso_full_X), columns = SVD_lasso_full_X.columns)\n",
    "\n",
    "y = processed_CLIs_df[['Overall_Survival']]\n",
    "SVD_lasso_full_X_train, SVD_lasso_full_X_test, y_train, y_test = train_test_split(SVD_lasso_full_X, y, test_size=0.2,random_state =42)\n",
    "#NN\n",
    "sc = StandardScaler()\n",
    "SVD_lasso_full_X_train = sc.fit_transform(SVD_lasso_full_X_train)\n",
    "SVD_lasso_full_X_test = sc.transform(SVD_lasso_full_X_test)\n",
    "\n",
    "''' Plot loss-iteration for (14, 24) '''\n",
    "SVD_full_lasso_NN_model = build_full_NN(18,14, 24)\n",
    "SVD_full_lasso_history = SVD_full_lasso_NN_model.fit(SVD_lasso_full_X_train, y_train, validation_data=(SVD_lasso_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_lasso_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_lasso_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_lasso_NN_model.predict(SVD_lasso_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, try SVD on both CLIs and genomic, instead on transforming genomic only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcga_participant_barcode</th>\n",
       "      <th>CLUS_mRNA_cNMF</th>\n",
       "      <th>CLUS_mRNA_cHierarchical</th>\n",
       "      <th>CLUS_miR_cNMF</th>\n",
       "      <th>CLUS_miR_cHierarchical</th>\n",
       "      <th>CLUS_CN_cNMF</th>\n",
       "      <th>CLUS_Methlyation_cNMF</th>\n",
       "      <th>CLUS_RPPA_cNMF</th>\n",
       "      <th>CLUS_RPPA_cHierarchical</th>\n",
       "      <th>CLUS_mRNAseq_cNMF</th>\n",
       "      <th>...</th>\n",
       "      <th>Del_SMYD3_1q44_mRNA</th>\n",
       "      <th>Del_TCL1A_14q24.2_mRNA</th>\n",
       "      <th>Del_TCL6_14q24.2_mRNA</th>\n",
       "      <th>Del_TFRC_3q29_mRNA</th>\n",
       "      <th>Del_TNFAIP3_6q22.1_mRNA</th>\n",
       "      <th>Del_TP53_17p13.1_mRNA</th>\n",
       "      <th>Del_TRIP11_14q24.2_mRNA</th>\n",
       "      <th>Del_TSHR_14q24.2_mRNA</th>\n",
       "      <th>Del_WIF1_12q15_mRNA</th>\n",
       "      <th>Del_WWOX_16q23.1_mRNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-02-0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-02-0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-02-0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-02-0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-02-0007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>TCGA-87-5896</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>TCGA-OX-A56R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>TCGA-RR-A6KA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>TCGA-RR-A6KB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TCGA-RR-A6KC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tcga_participant_barcode  CLUS_mRNA_cNMF  CLUS_mRNA_cHierarchical  \\\n",
       "0               TCGA-02-0001             1.0                      1.0   \n",
       "1               TCGA-02-0003             1.0                      1.0   \n",
       "2               TCGA-02-0004             1.0                      1.0   \n",
       "3               TCGA-02-0006             0.0                      0.0   \n",
       "4               TCGA-02-0007             2.0                      1.0   \n",
       "..                       ...             ...                      ...   \n",
       "590             TCGA-87-5896             3.0                      3.0   \n",
       "591             TCGA-OX-A56R             0.0                      0.0   \n",
       "592             TCGA-RR-A6KA             0.0                      0.0   \n",
       "593             TCGA-RR-A6KB             0.0                      0.0   \n",
       "594             TCGA-RR-A6KC             0.0                      0.0   \n",
       "\n",
       "     CLUS_miR_cNMF  CLUS_miR_cHierarchical  CLUS_CN_cNMF  \\\n",
       "0              1.0                     1.0           1.0   \n",
       "1              2.0                     1.0           2.0   \n",
       "2              1.0                     2.0           0.0   \n",
       "3              1.0                     2.0           1.0   \n",
       "4              2.0                     1.0           3.0   \n",
       "..             ...                     ...           ...   \n",
       "590            2.0                     3.0           2.0   \n",
       "591            0.0                     0.0           2.0   \n",
       "592            0.0                     0.0           1.0   \n",
       "593            0.0                     0.0           1.0   \n",
       "594            0.0                     0.0           3.0   \n",
       "\n",
       "     CLUS_Methlyation_cNMF  CLUS_RPPA_cNMF  CLUS_RPPA_cHierarchical  \\\n",
       "0                      1.0             0.0                      0.0   \n",
       "1                      2.0             1.0                      1.0   \n",
       "2                      0.0             2.0                      1.0   \n",
       "3                      1.0             0.0                      0.0   \n",
       "4                      3.0             0.0                      0.0   \n",
       "..                     ...             ...                      ...   \n",
       "590                    0.0             0.0                      0.0   \n",
       "591                    0.0             4.0                      1.0   \n",
       "592                    0.0             2.0                      1.0   \n",
       "593                    0.0             3.0                      2.0   \n",
       "594                    0.0             3.0                      3.0   \n",
       "\n",
       "     CLUS_mRNAseq_cNMF  ...  Del_SMYD3_1q44_mRNA  Del_TCL1A_14q24.2_mRNA  \\\n",
       "0                  0.0  ...                  0.0                     0.0   \n",
       "1                  0.0  ...                  0.0                     0.0   \n",
       "2                  0.0  ...                  0.0                     0.0   \n",
       "3                  0.0  ...                  0.0                     0.0   \n",
       "4                  0.0  ...                  0.0                     0.0   \n",
       "..                 ...  ...                  ...                     ...   \n",
       "590                0.0  ...                  0.0                     0.0   \n",
       "591                0.0  ...                  0.0                     0.0   \n",
       "592                0.0  ...                  0.0                     0.0   \n",
       "593                0.0  ...                  0.0                     0.0   \n",
       "594                0.0  ...                  0.0                     0.0   \n",
       "\n",
       "     Del_TCL6_14q24.2_mRNA  Del_TFRC_3q29_mRNA  Del_TNFAIP3_6q22.1_mRNA  \\\n",
       "0                      0.0                 0.0                      0.0   \n",
       "1                      0.0                 0.0                      0.0   \n",
       "2                      0.0                 0.0                      0.0   \n",
       "3                      0.0                 0.0                      0.0   \n",
       "4                      0.0                 0.0                      0.0   \n",
       "..                     ...                 ...                      ...   \n",
       "590                    0.0                 0.0                      0.0   \n",
       "591                    0.0                 0.0                      0.0   \n",
       "592                    0.0                 0.0                      0.0   \n",
       "593                    0.0                 0.0                      0.0   \n",
       "594                    0.0                 0.0                      0.0   \n",
       "\n",
       "     Del_TP53_17p13.1_mRNA  Del_TRIP11_14q24.2_mRNA  Del_TSHR_14q24.2_mRNA  \\\n",
       "0                      0.0                      0.0                    0.0   \n",
       "1                      0.0                      0.0                    0.0   \n",
       "2                      0.0                      0.0                    0.0   \n",
       "3                      0.0                      0.0                    0.0   \n",
       "4                      0.0                      0.0                    0.0   \n",
       "..                     ...                      ...                    ...   \n",
       "590                    0.0                      0.0                    0.0   \n",
       "591                    0.0                      0.0                    0.0   \n",
       "592                    0.0                      0.0                    0.0   \n",
       "593                    0.0                      0.0                    0.0   \n",
       "594                    0.0                      0.0                    0.0   \n",
       "\n",
       "     Del_WIF1_12q15_mRNA  Del_WWOX_16q23.1_mRNA  \n",
       "0                    0.0                    0.0  \n",
       "1                    0.0                    0.0  \n",
       "2                    0.0                    0.0  \n",
       "3                    0.0                    0.0  \n",
       "4                    0.0                    0.0  \n",
       "..                   ...                    ...  \n",
       "590                  0.0                    0.0  \n",
       "591                  0.0                    0.0  \n",
       "592                  0.0                    0.0  \n",
       "593                  0.0                    0.0  \n",
       "594                  0.0                    0.0  \n",
       "\n",
       "[595 rows x 649 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting genomic features\n",
    "genomic_df = df.drop(df.columns[range(1, 13)],axis=1,inplace=False)\n",
    "#fill null by 0\n",
    "genomic_df_0 = genomic_df.fillna(value=0, inplace = False)\n",
    "genomic_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "tcga_participant_barcode                                 0\n",
      "CLI_years_to_birth                                       0\n",
      "Overall_Survival                                         0\n",
      "CLI_date_of_initial_pathologic_diagnosis                 0\n",
      "CLI_karnofsky_performance_score                          0\n",
      "CLI_gender_male                                          0\n",
      "CLI_radiation_therapy_no                                 0\n",
      "CLI_radiation_therapy_yes                                0\n",
      "CLI_histological_type_glioblastoma multiforme (gbm)      0\n",
      "CLI_histological_type_treated primary gbm                0\n",
      "CLI_histological_type_untreated primary (de novo) gbm    0\n",
      "CLI_race_asian                                           0\n",
      "CLI_race_black or african american                       0\n",
      "CLI_race_white                                           0\n",
      "CLI_ethnicity_hispanic or latino                         0\n",
      "CLI_ethnicity_not hispanic or latino                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# on full_X\n",
    "#5 cols\n",
    "\n",
    "#getting genomic features\n",
    "genomic_df = df.drop(df.columns[range(1, 13)],axis=1,inplace=False)\n",
    "#fill null by 0\n",
    "genomic_df_0 = genomic_df.fillna(value=0, inplace = False)\n",
    "print(\"Missing values:\")\n",
    "print(genomic_df_0.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533307</td>\n",
       "      <td>-0.643082</td>\n",
       "      <td>-0.808512</td>\n",
       "      <td>0.373813</td>\n",
       "      <td>0.555538</td>\n",
       "      <td>-0.009167</td>\n",
       "      <td>0.060117</td>\n",
       "      <td>-0.035338</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>-0.046528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512881</td>\n",
       "      <td>-0.158090</td>\n",
       "      <td>0.068393</td>\n",
       "      <td>-0.482085</td>\n",
       "      <td>0.143708</td>\n",
       "      <td>-0.407102</td>\n",
       "      <td>0.214667</td>\n",
       "      <td>-0.564304</td>\n",
       "      <td>0.212719</td>\n",
       "      <td>-0.525007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086275</td>\n",
       "      <td>-0.411035</td>\n",
       "      <td>1.225090</td>\n",
       "      <td>2.171388</td>\n",
       "      <td>-0.587894</td>\n",
       "      <td>-0.694466</td>\n",
       "      <td>-0.309418</td>\n",
       "      <td>-0.271852</td>\n",
       "      <td>0.779320</td>\n",
       "      <td>-0.863759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426139</td>\n",
       "      <td>1.576901</td>\n",
       "      <td>1.762834</td>\n",
       "      <td>-0.623426</td>\n",
       "      <td>0.294990</td>\n",
       "      <td>-0.654937</td>\n",
       "      <td>-0.532052</td>\n",
       "      <td>-1.473255</td>\n",
       "      <td>0.674987</td>\n",
       "      <td>0.379543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454011</td>\n",
       "      <td>-0.634100</td>\n",
       "      <td>-0.555664</td>\n",
       "      <td>-0.287140</td>\n",
       "      <td>-0.326953</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.017480</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>-0.090045</td>\n",
       "      <td>0.038148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181280</td>\n",
       "      <td>-0.346559</td>\n",
       "      <td>-0.431076</td>\n",
       "      <td>-0.179947</td>\n",
       "      <td>-0.469600</td>\n",
       "      <td>0.055761</td>\n",
       "      <td>0.187730</td>\n",
       "      <td>-0.300616</td>\n",
       "      <td>0.151511</td>\n",
       "      <td>-0.193978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469417</td>\n",
       "      <td>-0.635864</td>\n",
       "      <td>-0.606133</td>\n",
       "      <td>-0.156124</td>\n",
       "      <td>-0.151267</td>\n",
       "      <td>-0.008652</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>-0.043271</td>\n",
       "      <td>-0.052463</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225538</td>\n",
       "      <td>0.264128</td>\n",
       "      <td>-0.084404</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.146837</td>\n",
       "      <td>0.419249</td>\n",
       "      <td>-0.487383</td>\n",
       "      <td>-1.016468</td>\n",
       "      <td>0.511439</td>\n",
       "      <td>-0.239481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553101</td>\n",
       "      <td>-0.645299</td>\n",
       "      <td>-0.874053</td>\n",
       "      <td>0.549188</td>\n",
       "      <td>0.790862</td>\n",
       "      <td>-0.029207</td>\n",
       "      <td>0.058974</td>\n",
       "      <td>-0.084867</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>-0.074423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083688</td>\n",
       "      <td>0.182089</td>\n",
       "      <td>0.075191</td>\n",
       "      <td>-0.306178</td>\n",
       "      <td>0.447147</td>\n",
       "      <td>0.444250</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>-0.162979</td>\n",
       "      <td>-0.717492</td>\n",
       "      <td>1.659145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-1.208440</td>\n",
       "      <td>-0.396771</td>\n",
       "      <td>1.485217</td>\n",
       "      <td>1.602703</td>\n",
       "      <td>1.085440</td>\n",
       "      <td>-1.685559</td>\n",
       "      <td>-0.298199</td>\n",
       "      <td>-0.610998</td>\n",
       "      <td>-1.161142</td>\n",
       "      <td>1.521020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342197</td>\n",
       "      <td>-0.648215</td>\n",
       "      <td>1.310735</td>\n",
       "      <td>-0.354242</td>\n",
       "      <td>-1.126117</td>\n",
       "      <td>0.920852</td>\n",
       "      <td>0.028591</td>\n",
       "      <td>0.391364</td>\n",
       "      <td>-0.179216</td>\n",
       "      <td>-0.323546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-0.657517</td>\n",
       "      <td>-0.397921</td>\n",
       "      <td>1.902518</td>\n",
       "      <td>-1.303821</td>\n",
       "      <td>2.221871</td>\n",
       "      <td>-1.164880</td>\n",
       "      <td>-0.956593</td>\n",
       "      <td>0.576941</td>\n",
       "      <td>1.336549</td>\n",
       "      <td>-3.052591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645074</td>\n",
       "      <td>0.848540</td>\n",
       "      <td>-0.052209</td>\n",
       "      <td>1.699522</td>\n",
       "      <td>0.517319</td>\n",
       "      <td>1.686058</td>\n",
       "      <td>1.242606</td>\n",
       "      <td>1.780273</td>\n",
       "      <td>-0.674329</td>\n",
       "      <td>-0.893523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-1.423946</td>\n",
       "      <td>-0.631484</td>\n",
       "      <td>-0.404256</td>\n",
       "      <td>-0.696895</td>\n",
       "      <td>-0.824144</td>\n",
       "      <td>-0.036739</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>-0.051314</td>\n",
       "      <td>0.091376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443567</td>\n",
       "      <td>0.085231</td>\n",
       "      <td>0.116384</td>\n",
       "      <td>-0.121958</td>\n",
       "      <td>-0.484354</td>\n",
       "      <td>-0.108813</td>\n",
       "      <td>0.080899</td>\n",
       "      <td>0.067661</td>\n",
       "      <td>-0.167273</td>\n",
       "      <td>0.172702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-1.444433</td>\n",
       "      <td>-0.629354</td>\n",
       "      <td>-0.340088</td>\n",
       "      <td>-0.871314</td>\n",
       "      <td>-1.057126</td>\n",
       "      <td>-0.019478</td>\n",
       "      <td>-0.014204</td>\n",
       "      <td>-0.021729</td>\n",
       "      <td>-0.135791</td>\n",
       "      <td>0.108955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043327</td>\n",
       "      <td>-0.101998</td>\n",
       "      <td>-0.341974</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>-0.397265</td>\n",
       "      <td>0.137033</td>\n",
       "      <td>-0.262329</td>\n",
       "      <td>-1.034095</td>\n",
       "      <td>0.632054</td>\n",
       "      <td>0.165645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>-0.989203</td>\n",
       "      <td>-0.638697</td>\n",
       "      <td>-0.619681</td>\n",
       "      <td>-0.121175</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>-0.065185</td>\n",
       "      <td>0.026784</td>\n",
       "      <td>-0.050889</td>\n",
       "      <td>0.052662</td>\n",
       "      <td>-0.004944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058296</td>\n",
       "      <td>0.151962</td>\n",
       "      <td>-0.075034</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>-1.066493</td>\n",
       "      <td>0.535510</td>\n",
       "      <td>0.301425</td>\n",
       "      <td>-0.319699</td>\n",
       "      <td>0.237002</td>\n",
       "      <td>0.443459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.533307 -0.643082 -0.808512  0.373813  0.555538 -0.009167  0.060117   \n",
       "1    0.086275 -0.411035  1.225090  2.171388 -0.587894 -0.694466 -0.309418   \n",
       "2    0.454011 -0.634100 -0.555664 -0.287140 -0.326953  0.001977  0.017480   \n",
       "3    0.469417 -0.635864 -0.606133 -0.156124 -0.151267 -0.008652  0.024145   \n",
       "4    0.553101 -0.645299 -0.874053  0.549188  0.790862 -0.029207  0.058974   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "485 -1.208440 -0.396771  1.485217  1.602703  1.085440 -1.685559 -0.298199   \n",
       "486 -0.657517 -0.397921  1.902518 -1.303821  2.221871 -1.164880 -0.956593   \n",
       "487 -1.423946 -0.631484 -0.404256 -0.696895 -0.824144 -0.036739 -0.002384   \n",
       "488 -1.444433 -0.629354 -0.340088 -0.871314 -1.057126 -0.019478 -0.014204   \n",
       "489 -0.989203 -0.638697 -0.619681 -0.121175 -0.065486 -0.065185  0.026784   \n",
       "\n",
       "           7         8         9   ...        40        41        42  \\\n",
       "0   -0.035338  0.014793 -0.046528  ...  0.512881 -0.158090  0.068393   \n",
       "1   -0.271852  0.779320 -0.863759  ... -0.426139  1.576901  1.762834   \n",
       "2    0.008534 -0.090045  0.038148  ...  0.181280 -0.346559 -0.431076   \n",
       "3   -0.043271 -0.052463  0.026716  ... -0.225538  0.264128 -0.084404   \n",
       "4   -0.084867  0.042356 -0.074423  ...  0.083688  0.182089  0.075191   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "485 -0.610998 -1.161142  1.521020  ...  0.342197 -0.648215  1.310735   \n",
       "486  0.576941  1.336549 -3.052591  ...  0.645074  0.848540 -0.052209   \n",
       "487 -0.029347 -0.051314  0.091376  ...  0.443567  0.085231  0.116384   \n",
       "488 -0.021729 -0.135791  0.108955  ...  0.043327 -0.101998 -0.341974   \n",
       "489 -0.050889  0.052662 -0.004944  ...  0.058296  0.151962 -0.075034   \n",
       "\n",
       "           43        44        45        46        47        48        49  \n",
       "0   -0.482085  0.143708 -0.407102  0.214667 -0.564304  0.212719 -0.525007  \n",
       "1   -0.623426  0.294990 -0.654937 -0.532052 -1.473255  0.674987  0.379543  \n",
       "2   -0.179947 -0.469600  0.055761  0.187730 -0.300616  0.151511 -0.193978  \n",
       "3    0.299800  0.146837  0.419249 -0.487383 -1.016468  0.511439 -0.239481  \n",
       "4   -0.306178  0.447147  0.444250  0.351667 -0.162979 -0.717492  1.659145  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "485 -0.354242 -1.126117  0.920852  0.028591  0.391364 -0.179216 -0.323546  \n",
       "486  1.699522  0.517319  1.686058  1.242606  1.780273 -0.674329 -0.893523  \n",
       "487 -0.121958 -0.484354 -0.108813  0.080899  0.067661 -0.167273  0.172702  \n",
       "488  0.387486 -0.397265  0.137033 -0.262329 -1.034095  0.632054  0.165645  \n",
       "489  0.024397 -1.066493  0.535510  0.301425 -0.319699  0.237002  0.443459  \n",
       "\n",
       "[490 rows x 50 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on full_X\n",
    "#5 cols\n",
    "#getting genomic features\n",
    "genomic_df = df.drop(df.columns[range(1, 13)],axis=1,inplace=False)\n",
    "#fill null by 0\n",
    "genomic_df_0 = genomic_df.fillna(value=0, inplace = False)\n",
    "full_X = pd.merge(processed_CLIs_df, genomic_df_0, on='tcga_participant_barcode', how='inner')\n",
    "full_X.drop(['tcga_participant_barcode', 'Overall_Survival'], axis=1, inplace = True)\n",
    "#SVD\n",
    "# Perform SVD matrix factorization to extract features\n",
    "SVD_full_X, s, V = np.linalg.svd(full_X.to_numpy(), full_matrices=False)\n",
    "SVD_full_X= pd.DataFrame(SVD_full_X[:, :50]) # Select the top 50 features out of 490 cols in U\n",
    "\n",
    "#normalization\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(SVD_full_X)\n",
    "SVD_full_X = pd.DataFrame(zscore_scaler.transform(SVD_full_X), columns = SVD_full_X.columns)\n",
    "SVD_full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train rmse, test rmse)=(398.75,508.25)\n"
     ]
    }
   ],
   "source": [
    "y = processed_CLIs_df[['Overall_Survival']]\n",
    "SVD_full_X_train, SVD_full_X_test, y_train, y_test = train_test_split(SVD_full_X, y, test_size=0.2,random_state =42)\n",
    "#NN\n",
    "sc = StandardScaler()\n",
    "SVD_full_X_train = sc.fit_transform(SVD_full_X_train)\n",
    "SVD_full_X_test = sc.transform(SVD_full_X_test)\n",
    "\n",
    "''' Plot loss-iteration for (14, 24) '''\n",
    "SVD_full_NN_model = build_full_NN(50,14, 24)\n",
    "SVD_full_history = SVD_full_NN_model.fit(SVD_full_X_train, y_train, validation_data=(SVD_full_X_test, y_test), batch_size = 10, epochs = 250, verbose = 0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(SVD_full_history.history[\"loss\"], label=\"training\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(SVD_full_history.history[\"val_loss\"], label=\"test\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "train_rms = mean_squared_error(y_train, SVD_full_NN_model.predict(SVD_full_X_train, verbose=0), squared=False)\n",
    "test_rms = mean_squared_error(y_test, SVD_full_NN_model.predict(SVD_full_X_test, verbose=0), squared=False)\n",
    "print(f\"(train rmse, test rmse)=({round(train_rms, 2)},{round(test_rms, 2)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(first_layer, second_layer, train rmse, test rmse)=(8,4,429.01,487.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,6,433.51,487.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,8,428.6,490.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,10,421.19,511.95)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,12,426.69,487.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,14,417.16,493.07)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,16,420.56,499.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,18,414.9,520.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,20,428.92,491.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,22,414.48,519.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(8,24,420.11,497.64)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,4,425.48,496.84)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,6,432.02,483.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,8,420.95,488.27)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,10,412.76,492.49)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,12,423.1,496.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,14,426.04,505.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,16,420.83,497.9)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,18,419.9,492.42)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,20,423.75,513.86)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,22,411.69,482.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(10,24,418.2,498.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,4,433.44,486.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,6,419.08,498.07)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,8,418.93,498.33)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,10,415.16,493.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,12,423.36,499.31)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,14,409.42,497.46)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,16,414.47,494.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,18,420.42,495.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,20,403.5,489.52)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,22,415.64,495.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(12,24,399.95,504.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,4,417.89,498.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,6,419.84,499.41)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,8,419.75,493.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,10,422.22,493.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,12,408.61,499.28)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,14,419.86,493.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,16,408.44,493.48)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,18,410.85,509.9)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,20,416.64,493.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,22,414.4,487.54)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(14,24,401.1,501.76)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,4,428.92,497.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,6,417.22,504.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,8,408.14,492.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,10,414.69,493.68)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,12,410.73,494.75)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,14,407.63,511.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,16,415.74,494.34)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,18,409.01,509.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,20,411.99,483.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,22,399.67,517.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(16,24,403.87,499.99)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,4,429.15,492.87)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,6,417.18,492.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,8,418.91,487.57)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,10,417.34,492.17)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,12,413.63,485.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,14,419.54,487.27)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,16,407.23,495.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,18,406.04,499.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,20,402.1,492.04)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,22,403.14,502.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(18,24,399.08,496.91)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,4,416.17,481.42)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,6,415.32,489.23)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,8,413.43,496.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,10,405.08,493.63)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,12,409.85,497.67)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,14,414.44,493.49)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,16,405.73,499.5)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,18,397.35,512.28)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,20,396.59,492.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,22,401.71,494.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(20,24,391.14,503.15)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,4,417.39,492.1)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,6,414.43,504.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,8,411.77,497.55)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,10,402.87,504.26)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,12,405.59,499.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,14,403.13,487.24)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,16,401.0,499.13)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,18,398.32,501.38)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,20,399.09,500.41)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,22,401.5,501.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(22,24,399.69,499.61)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,4,429.8,495.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,6,411.55,490.85)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,8,413.61,495.38)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,10,407.55,502.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,12,397.8,495.32)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,14,400.87,501.37)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,16,405.34,507.88)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,18,398.53,497.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,20,391.87,494.29)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,22,400.4,494.03)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(24,24,393.28,509.53)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,4,415.03,509.57)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,6,409.66,506.82)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,8,404.63,493.46)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,10,414.48,486.05)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,12,402.35,492.96)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,14,401.47,499.93)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,16,395.6,498.81)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,18,401.43,492.4)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,20,392.65,516.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,22,390.66,510.69)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(26,24,388.22,513.79)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,4,408.8,495.71)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,6,425.76,486.98)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,8,420.31,491.25)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,10,400.02,497.56)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,12,406.37,498.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,14,397.54,501.66)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,16,393.82,501.89)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,18,399.33,494.2)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,20,390.47,506.09)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,22,396.97,495.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(28,24,381.47,509.97)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,4,417.62,492.18)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,6,409.33,495.65)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,8,402.21,508.3)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,10,400.67,516.44)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,12,401.29,492.39)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,14,396.72,499.94)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,16,395.35,502.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,18,393.13,490.98)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,20,392.16,510.21)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,22,384.76,514.36)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(30,24,389.61,495.01)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,4,410.55,494.26)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,6,411.36,493.07)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,8,398.98,491.51)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,10,400.78,486.74)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,12,397.89,498.83)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,14,399.8,507.06)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,16,391.74,501.94)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,18,390.78,507.0)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,20,386.14,509.43)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,22,391.35,503.73)\n",
      "(first_layer, second_layer, train rmse, test rmse)=(32,24,393.26,498.92)\n"
     ]
    }
   ],
   "source": [
    "#try different number of units in each hidden layer\n",
    "num_hidden_unit= list()\n",
    "for  x in range(8, 34,2):\n",
    "    for y in range(4, 26,2):\n",
    "        num_hidden_unit.append((x,y))\n",
    "\n",
    "rmse_for_each_num_hidden = list()\n",
    "for a, b in num_hidden_unit:\n",
    "    SVD_full_NN_model = build_full_NN(50,a, b)\n",
    "    SVD_full_history = SVD_full_NN_model.fit(SVD_full_X_train, y_train, validation_data=(SVD_full_X_test, y_test), batch_size = 10, epochs = 150, verbose = 0)\n",
    "    train_rms = mean_squared_error(y_train, SVD_full_NN_model.predict(SVD_full_X_train, verbose=0), squared=False)\n",
    "    test_rms = mean_squared_error(y_test, SVD_full_NN_model.predict(SVD_full_X_test, verbose=0), squared=False)\n",
    "\n",
    "    print(f\"(first_layer, second_layer, train rmse, test rmse)=({a},{b},{round(train_rms, 2)},{round(test_rms, 2)})\")\n",
    "    rmse_for_each_num_hidden.append((a,b,train_rms,test_rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4, 416.16779954786955, 481.42392268727417)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_for_each_num_hidden, key = lambda t: t[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to dict\n",
    "rmse_dict = dict()\n",
    "for first_layer, second_layer, train_rmse, test_rmse in rmse_for_each_num_hidden:\n",
    "    rmse_dict[(first_layer, second_layer)] = test_rmse\n",
    "    \n",
    "plt.figure(figsize=(6, 4))\n",
    "# you should have a dictionary here.\n",
    "a3 = np.array([[rmse_dict[(first_layer, second_layer)] for first_layer in range(8, 34,2)] for second_layer in range(4, 26,2)])\n",
    "plt.title('hidden layer size')\n",
    "plt.imshow(a3, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=range(0, 13), labels=range(8, 34,2))\n",
    "plt.xlabel(\"first_layer_nodes\")\n",
    "plt.yticks(ticks=range(0, 11), labels=range(4, 26,2))\n",
    "plt.ylabel(\"second_layer_nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not as good as svd on genomic only==>keep it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
